[0m15:40:00.045856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d6562030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d694a2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d4c1c800>]}


============================== 15:40:00.060162 | caa071a1-10ff-484f-bd61-507dfcc2f327 ==============================
[0m15:40:00.060162 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:40:00.061154 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:40:00.108206 [info ] [MainThread]: dbt version: 1.8.9
[0m15:40:00.109144 [info ] [MainThread]: python version: 3.12.9
[0m15:40:00.109952 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:40:00.110635 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:40:00.111289 [info ] [MainThread]: Using profiles dir at /home/jovyan/.dbt
[0m15:40:00.111927 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/.dbt/profiles.yml
[0m15:40:00.112752 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:40:00.113389 [info ] [MainThread]: Configuration:
[0m15:40:00.113955 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m15:40:00.114568 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m15:40:00.115126 [info ] [MainThread]: Required dependencies:
[0m15:40:00.115745 [debug] [MainThread]: Executing "git --help"
[0m15:40:00.123583 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:40:00.124358 [debug] [MainThread]: STDERR: "b''"
[0m15:40:00.124812 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:40:00.125435 [info ] [MainThread]: Connection test skipped since no profile was found
[0m15:40:00.126133 [info ] [MainThread]: [31m2 checks failed:[0m
[0m15:40:00.126699 [info ] [MainThread]: dbt looked for a profiles.yml file in /home/jovyan/.dbt/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m15:40:00.127279 [info ] [MainThread]: Project loading failed for the following reason:
 project path </home/jovyan/dbt/workspace/dbt_project.yml> not found

[0m15:40:00.129058 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.18253571, "process_in_blocks": "30240", "process_kernel_time": 1.037468, "process_mem_max_rss": "95492", "process_out_blocks": "16", "process_user_time": 2.675042}
[0m15:40:00.130071 [debug] [MainThread]: Command `dbt debug` failed at 15:40:00.129827 after 0.18 seconds
[0m15:40:00.130742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d3e19010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d6562030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1d4270860>]}
[0m15:40:00.131411 [debug] [MainThread]: Flushing usage events
[0m15:40:39.192698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bc8bbef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bcef2de0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bcd15a60>]}


============================== 15:40:39.198651 | 6c34fa1a-0afd-4b79-9bff-ca3fac22e2c5 ==============================
[0m15:40:39.198651 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:40:39.200188 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m15:40:39.215799 [info ] [MainThread]: dbt version: 1.8.9
[0m15:40:39.217044 [info ] [MainThread]: python version: 3.12.9
[0m15:40:39.218036 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:40:39.218939 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:40:39.219972 [info ] [MainThread]: Using profiles dir at /home/jovyan/.dbt
[0m15:40:39.221276 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/.dbt/profiles.yml
[0m15:40:39.221939 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:40:39.222521 [info ] [MainThread]: Configuration:
[0m15:40:39.223204 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m15:40:39.224111 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m15:40:39.225051 [info ] [MainThread]: Required dependencies:
[0m15:40:39.226031 [debug] [MainThread]: Executing "git --help"
[0m15:40:39.229850 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:40:39.230705 [debug] [MainThread]: STDERR: "b''"
[0m15:40:39.231202 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:40:39.231778 [info ] [MainThread]: Connection test skipped since no profile was found
[0m15:40:39.233244 [info ] [MainThread]: [31m2 checks failed:[0m
[0m15:40:39.234213 [info ] [MainThread]: dbt looked for a profiles.yml file in /home/jovyan/.dbt/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m15:40:39.235131 [info ] [MainThread]: Project loading failed for the following reason:
 project path </home/jovyan/dbt/workspace/dbt_project.yml> not found

[0m15:40:39.237263 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.13902682, "process_in_blocks": "0", "process_kernel_time": 0.759115, "process_mem_max_rss": "95348", "process_out_blocks": "16", "process_user_time": 2.397205}
[0m15:40:39.238033 [debug] [MainThread]: Command `dbt debug` failed at 15:40:39.237872 after 0.14 seconds
[0m15:40:39.238879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bbaabe00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bcb9f860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87bd8c6660>]}
[0m15:40:39.239490 [debug] [MainThread]: Flushing usage events
[0m15:41:25.548413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe2135ff230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe212dba900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe213d06ba0>]}


============================== 15:41:25.555790 | c49d0baf-0d0b-4376-92bb-c690f8623bb8 ==============================
[0m15:41:25.555790 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:41:25.556799 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/jovyan/.dbt', 'log_path': 'logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:41:25.572414 [info ] [MainThread]: dbt version: 1.8.9
[0m15:41:25.573163 [info ] [MainThread]: python version: 3.12.9
[0m15:41:25.573813 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:41:25.574411 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:41:25.575158 [info ] [MainThread]: Using profiles dir at /home/jovyan/.dbt
[0m15:41:25.575917 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/.dbt/profiles.yml
[0m15:41:25.576512 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:41:25.577202 [info ] [MainThread]: Configuration:
[0m15:41:25.577855 [info ] [MainThread]:   profiles.yml file [[31mERROR not found[0m]
[0m15:41:25.578469 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m15:41:25.579068 [info ] [MainThread]: Required dependencies:
[0m15:41:25.579823 [debug] [MainThread]: Executing "git --help"
[0m15:41:25.583610 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:41:25.584288 [debug] [MainThread]: STDERR: "b''"
[0m15:41:25.584829 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:41:25.585697 [info ] [MainThread]: Connection test skipped since no profile was found
[0m15:41:25.586528 [info ] [MainThread]: [31m2 checks failed:[0m
[0m15:41:25.587485 [info ] [MainThread]: dbt looked for a profiles.yml file in /home/jovyan/.dbt/profiles.yml, but did
not find one. For more information on configuring your profile, consult the
documentation:

https://docs.getdbt.com/docs/configure-your-profile


[0m15:41:25.588167 [info ] [MainThread]: Project loading failed for the following reason:
 project path </home/jovyan/dbt/workspace/dbt_project.yml> not found

[0m15:41:25.589682 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.12986289, "process_in_blocks": "0", "process_kernel_time": 0.640246, "process_mem_max_rss": "95624", "process_out_blocks": "24", "process_user_time": 2.560987}
[0m15:41:25.590485 [debug] [MainThread]: Command `dbt debug` failed at 15:41:25.590320 after 0.13 seconds
[0m15:41:25.591284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe214c318e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe213d066c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe213594e30>]}
[0m15:41:25.591850 [debug] [MainThread]: Flushing usage events
[0m15:41:50.459204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5215596ff0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5216f66750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5214af0bf0>]}


============================== 15:41:50.466249 | 59638fce-7e3f-4efd-9b07-64854a877dcf ==============================
[0m15:41:50.466249 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:41:50.467269 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:41:50.482993 [info ] [MainThread]: dbt version: 1.8.9
[0m15:41:50.484162 [info ] [MainThread]: python version: 3.12.9
[0m15:41:50.485198 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:41:50.485830 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:41:50.641036 [info ] [MainThread]: Using profiles dir at /home/jovyan/dbt/workspace
[0m15:41:50.642264 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/dbt/workspace/profiles.yml
[0m15:41:50.643016 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:41:50.645968 [info ] [MainThread]: adapter type: clickhouse
[0m15:41:50.646706 [info ] [MainThread]: adapter version: 1.8.9
[0m15:41:50.647418 [info ] [MainThread]: Configuration:
[0m15:41:50.648221 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:41:50.649035 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m15:41:50.649960 [info ] [MainThread]: Required dependencies:
[0m15:41:50.650658 [debug] [MainThread]: Executing "git --help"
[0m15:41:50.654032 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:41:50.654874 [debug] [MainThread]: STDERR: "b''"
[0m15:41:50.655518 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:41:50.656111 [info ] [MainThread]: Connection:
[0m15:41:50.656752 [info ] [MainThread]:   driver: None
[0m15:41:50.657380 [info ] [MainThread]:   host: clickhouse
[0m15:41:50.657958 [info ] [MainThread]:   port: 8123
[0m15:41:50.658510 [info ] [MainThread]:   user: usuario_sak
[0m15:41:50.659194 [info ] [MainThread]:   schema: adw09_star
[0m15:41:50.660056 [info ] [MainThread]:   retries: 1
[0m15:41:50.660611 [info ] [MainThread]:   database_engine: None
[0m15:41:50.661144 [info ] [MainThread]:   cluster_mode: False
[0m15:41:50.661698 [info ] [MainThread]:   secure: False
[0m15:41:50.662210 [info ] [MainThread]:   verify: True
[0m15:41:50.662730 [info ] [MainThread]:   client_cert: None
[0m15:41:50.663255 [info ] [MainThread]:   client_cert_key: None
[0m15:41:50.663833 [info ] [MainThread]:   connect_timeout: 10
[0m15:41:50.664682 [info ] [MainThread]:   send_receive_timeout: 300
[0m15:41:50.665519 [info ] [MainThread]:   sync_request_timeout: 5
[0m15:41:50.666048 [info ] [MainThread]:   compress_block_size: 1048576
[0m15:41:50.666675 [info ] [MainThread]:   compression: 
[0m15:41:50.667177 [info ] [MainThread]:   check_exchange: True
[0m15:41:50.667690 [info ] [MainThread]:   custom_settings: None
[0m15:41:50.668196 [info ] [MainThread]:   use_lw_deletes: False
[0m15:41:50.668741 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m15:41:50.669381 [info ] [MainThread]:   tcp_keepalive: False
[0m15:41:50.670422 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:41:50.827361 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m15:41:50.828185 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:41:53.009048 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m15:41:53.010100 [info ] [MainThread]: [31m2 checks failed:[0m
[0m15:41:53.010881 [info ] [MainThread]: Project loading failed for the following reason:
 project path </home/jovyan/dbt/workspace/dbt_project.yml> not found

[0m15:41:53.011671 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 516
   Code: 516. DB::Exception: usuario_sak: Authentication failed: password is incorrect, or there is no user with such name. (AUTHENTICATION_FAILED) (version 25.4.1.2934 (official build))
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m15:41:53.013595 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 2.6474402, "process_in_blocks": "155888", "process_kernel_time": 1.365368, "process_mem_max_rss": "187324", "process_out_blocks": "32", "process_user_time": 4.983097}
[0m15:41:53.014668 [debug] [MainThread]: Command `dbt debug` failed at 15:41:53.014337 after 2.65 seconds
[0m15:41:53.015683 [debug] [MainThread]: Connection 'debug' was left open.
[0m15:41:53.016329 [debug] [MainThread]: On debug: No close available on handle
[0m15:41:53.017435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5215241310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5215205d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f521599b530>]}
[0m15:41:53.018609 [debug] [MainThread]: Flushing usage events
[0m15:46:51.364135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cdd48c9b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cdcb1a0c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cdd48fc80>]}


============================== 15:46:51.377775 | f45009e1-bb39-44f9-a429-721e3d176ab9 ==============================
[0m15:46:51.377775 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:46:51.378731 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/jovyan/dbt/workspace', 'log_path': 'logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m15:46:51.398143 [info ] [MainThread]: dbt version: 1.8.9
[0m15:46:51.399129 [info ] [MainThread]: python version: 3.12.9
[0m15:46:51.399868 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:46:51.400604 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:46:51.542438 [info ] [MainThread]: Using profiles dir at /home/jovyan/dbt/workspace
[0m15:46:51.543539 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/dbt/workspace/profiles.yml
[0m15:46:51.544407 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:46:51.545662 [info ] [MainThread]: adapter type: clickhouse
[0m15:46:51.547139 [info ] [MainThread]: adapter version: 1.8.9
[0m15:46:51.547875 [info ] [MainThread]: Configuration:
[0m15:46:51.548590 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:46:51.549446 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m15:46:51.550284 [info ] [MainThread]: Required dependencies:
[0m15:46:51.550856 [debug] [MainThread]: Executing "git --help"
[0m15:46:51.554083 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:46:51.554772 [debug] [MainThread]: STDERR: "b''"
[0m15:46:51.555251 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:46:51.555914 [info ] [MainThread]: Connection:
[0m15:46:51.556713 [info ] [MainThread]:   driver: None
[0m15:46:51.557232 [info ] [MainThread]:   host: clickhouse
[0m15:46:51.557805 [info ] [MainThread]:   port: 8123
[0m15:46:51.558349 [info ] [MainThread]:   user: usuario_sak
[0m15:46:51.558842 [info ] [MainThread]:   schema: adw09_star
[0m15:46:51.559519 [info ] [MainThread]:   retries: 1
[0m15:46:51.560286 [info ] [MainThread]:   database_engine: None
[0m15:46:51.560900 [info ] [MainThread]:   cluster_mode: False
[0m15:46:51.561476 [info ] [MainThread]:   secure: False
[0m15:46:51.561995 [info ] [MainThread]:   verify: True
[0m15:46:51.562488 [info ] [MainThread]:   client_cert: None
[0m15:46:51.563106 [info ] [MainThread]:   client_cert_key: None
[0m15:46:51.563688 [info ] [MainThread]:   connect_timeout: 10
[0m15:46:51.564189 [info ] [MainThread]:   send_receive_timeout: 300
[0m15:46:51.564726 [info ] [MainThread]:   sync_request_timeout: 5
[0m15:46:51.565287 [info ] [MainThread]:   compress_block_size: 1048576
[0m15:46:51.565836 [info ] [MainThread]:   compression: 
[0m15:46:51.566561 [info ] [MainThread]:   check_exchange: True
[0m15:46:51.567252 [info ] [MainThread]:   custom_settings: None
[0m15:46:51.567850 [info ] [MainThread]:   use_lw_deletes: False
[0m15:46:51.568500 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m15:46:51.569223 [info ] [MainThread]:   tcp_keepalive: False
[0m15:46:51.570128 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:46:51.716978 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m15:46:51.717668 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:46:52.855902 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m15:46:52.862543 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:46:52.891205 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:46:52.892256 [info ] [MainThread]: [31m1 check failed:[0m
[0m15:46:52.892988 [info ] [MainThread]: Project loading failed for the following reason:
 project path </home/jovyan/dbt/workspace/dbt_project.yml> not found

[0m15:46:52.894827 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 1.6226056, "process_in_blocks": "288", "process_kernel_time": 1.268423, "process_mem_max_rss": "192444", "process_out_blocks": "24", "process_user_time": 5.12324}
[0m15:46:52.895513 [debug] [MainThread]: Command `dbt debug` failed at 15:46:52.895344 after 1.62 seconds
[0m15:46:52.896112 [debug] [MainThread]: Connection 'debug' was left open.
[0m15:46:52.896600 [debug] [MainThread]: On debug: Close
[0m15:46:52.897240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cdd4dc380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cdd8e2960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6cdc543da0>]}
[0m15:46:52.897798 [debug] [MainThread]: Flushing usage events
[0m15:47:50.668333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42938845f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f429228d100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4291c1ff50>]}


============================== 15:47:50.673605 | 19efda63-57b1-409e-9ed6-bfa660b8fdaf ==============================
[0m15:47:50.673605 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:47:50.674504 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'version_check': 'True', 'profiles_dir': '/home/jovyan/dbt/workspace', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:47:50.688662 [info ] [MainThread]: dbt version: 1.8.9
[0m15:47:50.689413 [info ] [MainThread]: python version: 3.12.9
[0m15:47:50.690074 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:47:50.690755 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:47:50.809399 [info ] [MainThread]: Using profiles dir at /home/jovyan/dbt/workspace
[0m15:47:50.810308 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/dbt/workspace/profiles.yml
[0m15:47:50.810972 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:47:50.812002 [info ] [MainThread]: adapter type: clickhouse
[0m15:47:50.812567 [info ] [MainThread]: adapter version: 1.8.9
[0m15:47:50.971549 [info ] [MainThread]: Configuration:
[0m15:47:50.972400 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:47:50.973065 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m15:47:50.973669 [info ] [MainThread]: Required dependencies:
[0m15:47:50.974383 [debug] [MainThread]: Executing "git --help"
[0m15:47:50.977855 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:47:50.978668 [debug] [MainThread]: STDERR: "b''"
[0m15:47:50.979131 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:47:50.979853 [info ] [MainThread]: Connection:
[0m15:47:50.980563 [info ] [MainThread]:   driver: None
[0m15:47:50.981338 [info ] [MainThread]:   host: clickhouse
[0m15:47:50.982027 [info ] [MainThread]:   port: 8123
[0m15:47:50.982742 [info ] [MainThread]:   user: usuario_sak
[0m15:47:50.983285 [info ] [MainThread]:   schema: adw09_star
[0m15:47:50.983853 [info ] [MainThread]:   retries: 1
[0m15:47:50.984422 [info ] [MainThread]:   database_engine: None
[0m15:47:50.984962 [info ] [MainThread]:   cluster_mode: False
[0m15:47:50.985489 [info ] [MainThread]:   secure: False
[0m15:47:50.986070 [info ] [MainThread]:   verify: True
[0m15:47:50.986650 [info ] [MainThread]:   client_cert: None
[0m15:47:50.987188 [info ] [MainThread]:   client_cert_key: None
[0m15:47:50.987725 [info ] [MainThread]:   connect_timeout: 10
[0m15:47:50.988409 [info ] [MainThread]:   send_receive_timeout: 300
[0m15:47:50.989034 [info ] [MainThread]:   sync_request_timeout: 5
[0m15:47:50.989598 [info ] [MainThread]:   compress_block_size: 1048576
[0m15:47:50.990445 [info ] [MainThread]:   compression: 
[0m15:47:50.991066 [info ] [MainThread]:   check_exchange: True
[0m15:47:50.991734 [info ] [MainThread]:   custom_settings: None
[0m15:47:50.992453 [info ] [MainThread]:   use_lw_deletes: False
[0m15:47:50.993052 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m15:47:50.993571 [info ] [MainThread]:   tcp_keepalive: False
[0m15:47:50.994651 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:47:51.129114 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m15:47:51.129838 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:47:52.112143 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m15:47:52.118226 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:47:52.143958 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:47:52.144945 [info ] [MainThread]: [32mAll checks passed![0m
[0m15:47:52.146994 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.5675288, "process_in_blocks": "0", "process_kernel_time": 1.04153, "process_mem_max_rss": "195628", "process_out_blocks": "24", "process_user_time": 4.830715}
[0m15:47:52.148174 [debug] [MainThread]: Command `dbt debug` succeeded at 15:47:52.147935 after 1.57 seconds
[0m15:47:52.148812 [debug] [MainThread]: Connection 'debug' was left open.
[0m15:47:52.149294 [debug] [MainThread]: On debug: Close
[0m15:47:52.150111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4292cb5c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42917caf30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42217d4d40>]}
[0m15:47:52.150752 [debug] [MainThread]: Flushing usage events
[0m15:48:01.447566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9c163e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9ceb2cf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9c193350>]}


============================== 15:48:01.453211 | 497e4067-b7fb-4e01-81dc-3255d826ca50 ==============================
[0m15:48:01.453211 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:48:01.454333 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/jovyan/dbt/workspace/logs', 'profiles_dir': '/home/jovyan/dbt/workspace', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:48:01.996470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9d33de20>]}
[0m15:48:02.098097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9bde1220>]}
[0m15:48:02.100056 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:48:02.256117 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m15:48:02.257512 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:48:02.258391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9bd14950>]}
[0m15:48:05.020467 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m15:48:05.021369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9bf38da0>]}
[0m15:48:05.589750 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_rental' in the 'models' section of file 'models/marts/staging/stg_rentals.yml'
[0m15:48:05.800081 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.staging
[0m15:48:05.819801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9b8d32c0>]}
[0m15:48:06.051187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9b86c050>]}
[0m15:48:06.052003 [info ] [MainThread]: Found 15 models, 1 snapshot, 23 data tests, 13 sources, 475 macros
[0m15:48:06.052672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9d40e4b0>]}
[0m15:48:06.057521 [info ] [MainThread]: 
[0m15:48:06.058906 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:48:06.071590 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:48:06.091048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:07.017799 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:48:07.023405 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:48:07.060076 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:48:07.065497 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:48:07.068260 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__adw09_star_adw09_stag)
[0m15:48:07.069116 [debug] [ThreadPool]: Creating schema "schema: "adw09_star_adw09_stag"
"
[0m15:48:07.082618 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_star_adw09_stag"} */
create database if not exists `adw09_star_adw09_stag`
        
  
        
  ...
[0m15:48:07.092865 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:48:07.095069 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_star_adw09_stag, now create__adw09_star_adw09_star)
[0m15:48:07.095914 [debug] [ThreadPool]: Creating schema "schema: "adw09_star_adw09_star"
"
[0m15:48:07.102024 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_star_adw09_star"} */
create database if not exists `adw09_star_adw09_star`
        
  
        
  ...
[0m15:48:07.113926 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:48:07.119128 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_star_adw09_star, now list__adw09_star_adw09_stag)
[0m15:48:07.131338 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_stag'
      

  ...
[0m15:48:07.168900 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m15:48:07.171604 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_stag, now list__adw09_star)
[0m15:48:07.176452 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m15:48:07.206879 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:48:07.210277 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__adw09_star_adw09_star)
[0m15:48:07.214903 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_star'
      

  ...
[0m15:48:07.240366 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:48:07.244023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9b911df0>]}
[0m15:48:07.245097 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m15:48:07.245901 [info ] [MainThread]: 
[0m15:48:07.253541 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m15:48:07.254543 [info ] [Thread-1 (]: 1 of 15 START sql view model `adw09_star_adw09_stag`.`stg_customer` ............ [RUN]
[0m15:48:07.255382 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_star, now model.sakstar.stg_customer)
[0m15:48:07.256006 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m15:48:07.287233 [debug] [Thread-1 (]: Compilation Error in model stg_customer (models/marts/staging/stg_customer.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.290225 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a74ef00>]}
[0m15:48:07.291778 [error] [Thread-1 (]: 1 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_customer` ... [[31mERROR[0m in 0.03s]
[0m15:48:07.293181 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m15:48:07.294068 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer-checkpoint
[0m15:48:07.295042 [info ] [Thread-1 (]: 2 of 15 START sql view model `adw09_star_adw09_stag`.`stg_customer-checkpoint` . [RUN]
[0m15:48:07.297978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_customer-checkpoint)
[0m15:48:07.298830 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer-checkpoint
[0m15:48:07.310230 [debug] [Thread-1 (]: Compilation Error in model stg_customer-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.311194 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a18cb10d0>]}
[0m15:48:07.312352 [error] [Thread-1 (]: 2 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_customer-checkpoint`  [[31mERROR[0m in 0.01s]
[0m15:48:07.313370 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer-checkpoint
[0m15:48:07.314278 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m15:48:07.315122 [info ] [Thread-1 (]: 3 of 15 START sql view model `adw09_star_adw09_stag`.`stg_film` ................ [RUN]
[0m15:48:07.316385 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer-checkpoint, now model.sakstar.stg_film)
[0m15:48:07.316994 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m15:48:07.326732 [debug] [Thread-1 (]: Compilation Error in model stg_film (models/marts/staging/stg_film.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.327646 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a77f320>]}
[0m15:48:07.328766 [error] [Thread-1 (]: 3 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_film` ....... [[31mERROR[0m in 0.01s]
[0m15:48:07.330045 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m15:48:07.330890 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film-checkpoint
[0m15:48:07.332059 [info ] [Thread-1 (]: 4 of 15 START sql view model `adw09_star_adw09_stag`.`stg_film-checkpoint` ..... [RUN]
[0m15:48:07.333336 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_film-checkpoint)
[0m15:48:07.334146 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film-checkpoint
[0m15:48:07.344156 [debug] [Thread-1 (]: Compilation Error in model stg_film-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.345129 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a18cd8530>]}
[0m15:48:07.346205 [error] [Thread-1 (]: 4 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_film-checkpoint`  [[31mERROR[0m in 0.01s]
[0m15:48:07.347353 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film-checkpoint
[0m15:48:07.348210 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m15:48:07.349199 [info ] [Thread-1 (]: 5 of 15 START sql view model `adw09_star_adw09_stag`.`stg_rentals` ............. [RUN]
[0m15:48:07.350645 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film-checkpoint, now model.sakstar.stg_rentals)
[0m15:48:07.351396 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m15:48:07.363977 [debug] [Thread-1 (]: Compilation Error in model stg_rentals (models/marts/staging/stg_rentals.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.364829 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a18cc5520>]}
[0m15:48:07.365807 [error] [Thread-1 (]: 5 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_rentals` .... [[31mERROR[0m in 0.01s]
[0m15:48:07.366907 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m15:48:07.367735 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals-checkpoint
[0m15:48:07.369224 [info ] [Thread-1 (]: 6 of 15 START sql view model `adw09_star_adw09_stag`.`stg_rentals-checkpoint` .. [RUN]
[0m15:48:07.370302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_rentals-checkpoint)
[0m15:48:07.370873 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals-checkpoint
[0m15:48:07.380600 [debug] [Thread-1 (]: Compilation Error in model stg_rentals-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.381412 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a64ade0>]}
[0m15:48:07.382492 [error] [Thread-1 (]: 6 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_rentals-checkpoint`  [[31mERROR[0m in 0.01s]
[0m15:48:07.383668 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals-checkpoint
[0m15:48:07.384472 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m15:48:07.385808 [info ] [Thread-1 (]: 7 of 15 START sql view model `adw09_star_adw09_stag`.`stg_staff` ............... [RUN]
[0m15:48:07.386823 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals-checkpoint, now model.sakstar.stg_staff)
[0m15:48:07.387399 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m15:48:07.397129 [debug] [Thread-1 (]: Compilation Error in model stg_staff (models/marts/staging/stg_staff.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.398025 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a622cf0>]}
[0m15:48:07.399347 [error] [Thread-1 (]: 7 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_staff` ...... [[31mERROR[0m in 0.01s]
[0m15:48:07.401338 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m15:48:07.402550 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff-checkpoint
[0m15:48:07.404340 [info ] [Thread-1 (]: 8 of 15 START sql view model `adw09_star_adw09_stag`.`stg_staff-checkpoint` .... [RUN]
[0m15:48:07.406088 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_staff-checkpoint)
[0m15:48:07.406804 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff-checkpoint
[0m15:48:07.416045 [debug] [Thread-1 (]: Compilation Error in model stg_staff-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.416836 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a6054f0>]}
[0m15:48:07.417939 [error] [Thread-1 (]: 8 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_staff-checkpoint`  [[31mERROR[0m in 0.01s]
[0m15:48:07.418926 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff-checkpoint
[0m15:48:07.419739 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m15:48:07.421125 [info ] [Thread-1 (]: 9 of 15 START sql view model `adw09_star_adw09_stag`.`stg_store` ............... [RUN]
[0m15:48:07.422002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff-checkpoint, now model.sakstar.stg_store)
[0m15:48:07.422651 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m15:48:07.434858 [debug] [Thread-1 (]: Compilation Error in model stg_store (models/marts/staging/stg_store.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.435664 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a77cb90>]}
[0m15:48:07.436558 [error] [Thread-1 (]: 9 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_store` ...... [[31mERROR[0m in 0.01s]
[0m15:48:07.437749 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m15:48:07.438464 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store-checkpoint
[0m15:48:07.439298 [info ] [Thread-1 (]: 10 of 15 START sql view model `adw09_star_adw09_stag`.`stg_store-checkpoint` ... [RUN]
[0m15:48:07.440275 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.stg_store-checkpoint)
[0m15:48:07.441098 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store-checkpoint
[0m15:48:07.454266 [debug] [Thread-1 (]: Compilation Error in model stg_store-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.455084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '497e4067-b7fb-4e01-81dc-3255d826ca50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a1a6e1e20>]}
[0m15:48:07.456013 [error] [Thread-1 (]: 10 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_store-checkpoint`  [[31mERROR[0m in 0.01s]
[0m15:48:07.457042 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store-checkpoint
[0m15:48:07.457823 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m15:48:07.458684 [info ] [Thread-1 (]: 11 of 15 SKIP relation adw09_star_adw09_star.dim_customer ...................... [[33mSKIP[0m]
[0m15:48:07.460187 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m15:48:07.461241 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m15:48:07.462446 [info ] [Thread-1 (]: 12 of 15 SKIP relation adw09_star_adw09_star.dim_film .......................... [[33mSKIP[0m]
[0m15:48:07.463669 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m15:48:07.464700 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m15:48:07.465578 [info ] [Thread-1 (]: 13 of 15 SKIP relation adw09_star_adw09_star.dim_staff ......................... [[33mSKIP[0m]
[0m15:48:07.466790 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m15:48:07.467680 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m15:48:07.468693 [info ] [Thread-1 (]: 14 of 15 SKIP relation adw09_star_adw09_star.dim_store ......................... [[33mSKIP[0m]
[0m15:48:07.469653 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m15:48:07.471604 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m15:48:07.472476 [info ] [Thread-1 (]: 15 of 15 SKIP relation adw09_star_adw09_star.fct_rentals ....................... [[33mSKIP[0m]
[0m15:48:07.473513 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m15:48:07.476971 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:48:07.477659 [debug] [MainThread]: Connection 'model.sakstar.stg_store-checkpoint' was left open.
[0m15:48:07.478224 [debug] [MainThread]: On model.sakstar.stg_store-checkpoint: Close
[0m15:48:07.479326 [info ] [MainThread]: 
[0m15:48:07.480160 [info ] [MainThread]: Finished running 10 view models, 5 incremental models in 0 hours 0 minutes and 1.42 seconds (1.42s).
[0m15:48:07.483225 [debug] [MainThread]: Command end result
[0m15:48:07.550600 [info ] [MainThread]: 
[0m15:48:07.551973 [info ] [MainThread]: [31mCompleted with 10 errors and 0 warnings:[0m
[0m15:48:07.552830 [info ] [MainThread]: 
[0m15:48:07.553823 [error] [MainThread]:   Compilation Error in model stg_customer (models/marts/staging/stg_customer.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.554524 [info ] [MainThread]: 
[0m15:48:07.555306 [error] [MainThread]:   Compilation Error in model stg_customer-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.555912 [info ] [MainThread]: 
[0m15:48:07.556772 [error] [MainThread]:   Compilation Error in model stg_film (models/marts/staging/stg_film.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.557414 [info ] [MainThread]: 
[0m15:48:07.558238 [error] [MainThread]:   Compilation Error in model stg_film-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.559203 [info ] [MainThread]: 
[0m15:48:07.560374 [error] [MainThread]:   Compilation Error in model stg_rentals (models/marts/staging/stg_rentals.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.561042 [info ] [MainThread]: 
[0m15:48:07.562018 [error] [MainThread]:   Compilation Error in model stg_rentals-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.562740 [info ] [MainThread]: 
[0m15:48:07.563627 [error] [MainThread]:   Compilation Error in model stg_staff (models/marts/staging/stg_staff.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.564376 [info ] [MainThread]: 
[0m15:48:07.565113 [error] [MainThread]:   Compilation Error in model stg_staff-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.565736 [info ] [MainThread]: 
[0m15:48:07.566646 [error] [MainThread]:   Compilation Error in model stg_store (models/marts/staging/stg_store.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.567398 [info ] [MainThread]: 
[0m15:48:07.568356 [error] [MainThread]:   Compilation Error in model stg_store-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:48:07.569084 [info ] [MainThread]: 
[0m15:48:07.569954 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=10 SKIP=5 TOTAL=15
[0m15:48:07.571862 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.207276, "process_in_blocks": "4032", "process_kernel_time": 1.206772, "process_mem_max_rss": "206948", "process_out_blocks": "3960", "process_user_time": 9.362544}
[0m15:48:07.572783 [debug] [MainThread]: Command `dbt run` failed at 15:48:07.572569 after 6.21 seconds
[0m15:48:07.573534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9c163e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a9c1ebb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a25ae8560>]}
[0m15:48:07.574213 [debug] [MainThread]: Flushing usage events
[0m15:48:39.474708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4045c82f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc403b0e390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc404184890>]}


============================== 15:48:39.481879 | 1dce41cf-a1e6-4e8a-84d8-50b544b5e7ed ==============================
[0m15:48:39.481879 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:48:39.483247 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/jovyan/dbt/workspace/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:48:39.720543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1dce41cf-a1e6-4e8a-84d8-50b544b5e7ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc403643bf0>]}
[0m15:48:39.760988 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:48:39.763090 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:48:39.764936 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.38210672, "process_in_blocks": "192", "process_kernel_time": 0.757612, "process_mem_max_rss": "97000", "process_out_blocks": "8", "process_user_time": 2.731391}
[0m15:48:39.765843 [debug] [MainThread]: Command `dbt deps` succeeded at 15:48:39.765638 after 0.38 seconds
[0m15:48:39.766424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4045c82f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc403321340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4036ba900>]}
[0m15:48:39.767011 [debug] [MainThread]: Flushing usage events
[0m15:52:31.831714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f659017d4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65902e20c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65902e2540>]}


============================== 15:52:31.837517 | 57c60fc8-0f46-47cf-a2fa-f7f206993231 ==============================
[0m15:52:31.837517 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:52:31.838879 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/jovyan/dbt/workspace', 'log_path': '/home/jovyan/dbt/workspace/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m15:52:32.057092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '57c60fc8-0f46-47cf-a2fa-f7f206993231', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f659191cfe0>]}
[0m15:52:32.079409 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-zi0mfs75'
[0m15:52:32.080822 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m15:52:32.473421 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m15:52:32.474695 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m15:52:32.581845 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m15:52:32.593265 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m15:52:32.991135 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m15:52:33.011545 [info ] [MainThread]: Updating lock file in file path: /home/jovyan/dbt/workspace/package-lock.yml
[0m15:52:33.015997 [debug] [MainThread]: Set downloads directory='/tmp/dbt-downloads-yxk40yuh'
[0m15:52:33.023191 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m15:52:33.729364 [info ] [MainThread]: Installed from version 1.1.1
[0m15:52:33.730357 [info ] [MainThread]: Updated version available: 1.3.0
[0m15:52:33.731343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '57c60fc8-0f46-47cf-a2fa-f7f206993231', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f658ff494c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f658ff29c10>]}
[0m15:52:33.732061 [info ] [MainThread]: Installing dbt-labs/codegen
[0m15:52:34.149436 [info ] [MainThread]: Installed from version 0.11.0
[0m15:52:34.150619 [info ] [MainThread]: Updated version available: 0.13.1
[0m15:52:34.151398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '57c60fc8-0f46-47cf-a2fa-f7f206993231', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f658fcaffb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f658fcaff50>]}
[0m15:52:34.152011 [info ] [MainThread]: 
[0m15:52:34.152725 [info ] [MainThread]: Updates available for packages: ['dbt-labs/dbt_utils', 'dbt-labs/codegen']                 
Update your versions in packages.yml, then run dbt deps
[0m15:52:34.155094 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 2.4084666, "process_in_blocks": "8", "process_kernel_time": 0.707237, "process_mem_max_rss": "98324", "process_out_blocks": "2944", "process_user_time": 2.869362}
[0m15:52:34.155817 [debug] [MainThread]: Command `dbt deps` succeeded at 15:52:34.155652 after 2.41 seconds
[0m15:52:34.156372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65901d8b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65901d8aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6590da5fa0>]}
[0m15:52:34.156971 [debug] [MainThread]: Flushing usage events
[0m15:52:45.327199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6176bba930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f617616c170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f617575deb0>]}


============================== 15:52:45.332888 | a505523b-641e-435a-9b1b-051ffa972703 ==============================
[0m15:52:45.332888 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:52:45.333981 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'fail_fast': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:52:45.352976 [info ] [MainThread]: dbt version: 1.8.9
[0m15:52:45.353880 [info ] [MainThread]: python version: 3.12.9
[0m15:52:45.354691 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m15:52:45.355292 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m15:52:45.481107 [info ] [MainThread]: Using profiles dir at /home/jovyan/dbt/workspace
[0m15:52:45.481974 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/dbt/workspace/profiles.yml
[0m15:52:45.482614 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m15:52:45.483615 [info ] [MainThread]: adapter type: clickhouse
[0m15:52:45.484228 [info ] [MainThread]: adapter version: 1.8.9
[0m15:52:45.688866 [info ] [MainThread]: Configuration:
[0m15:52:45.689965 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:52:45.690651 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m15:52:45.691391 [info ] [MainThread]: Required dependencies:
[0m15:52:45.692288 [debug] [MainThread]: Executing "git --help"
[0m15:52:45.695915 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:52:45.696552 [debug] [MainThread]: STDERR: "b''"
[0m15:52:45.697047 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:52:45.697653 [info ] [MainThread]: Connection:
[0m15:52:45.698312 [info ] [MainThread]:   driver: None
[0m15:52:45.698980 [info ] [MainThread]:   host: clickhouse
[0m15:52:45.699551 [info ] [MainThread]:   port: 8123
[0m15:52:45.700457 [info ] [MainThread]:   user: usuario_sak
[0m15:52:45.701083 [info ] [MainThread]:   schema: adw09_star
[0m15:52:45.701727 [info ] [MainThread]:   retries: 1
[0m15:52:45.702334 [info ] [MainThread]:   database_engine: None
[0m15:52:45.702980 [info ] [MainThread]:   cluster_mode: False
[0m15:52:45.703726 [info ] [MainThread]:   secure: False
[0m15:52:45.704493 [info ] [MainThread]:   verify: True
[0m15:52:45.705270 [info ] [MainThread]:   client_cert: None
[0m15:52:45.705903 [info ] [MainThread]:   client_cert_key: None
[0m15:52:45.706444 [info ] [MainThread]:   connect_timeout: 10
[0m15:52:45.707244 [info ] [MainThread]:   send_receive_timeout: 300
[0m15:52:45.708142 [info ] [MainThread]:   sync_request_timeout: 5
[0m15:52:45.708838 [info ] [MainThread]:   compress_block_size: 1048576
[0m15:52:45.709405 [info ] [MainThread]:   compression: 
[0m15:52:45.710105 [info ] [MainThread]:   check_exchange: True
[0m15:52:45.710855 [info ] [MainThread]:   custom_settings: None
[0m15:52:45.711567 [info ] [MainThread]:   use_lw_deletes: False
[0m15:52:45.712223 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m15:52:45.712849 [info ] [MainThread]:   tcp_keepalive: False
[0m15:52:45.713795 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:52:45.869340 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m15:52:45.870227 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:52:46.858245 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m15:52:46.864024 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:52:46.893218 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:52:46.894223 [info ] [MainThread]: [32mAll checks passed![0m
[0m15:52:46.896353 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.6707953, "process_in_blocks": "0", "process_kernel_time": 0.904792, "process_mem_max_rss": "193564", "process_out_blocks": "16", "process_user_time": 5.207583}
[0m15:52:46.897233 [debug] [MainThread]: Command `dbt debug` succeeded at 15:52:46.896931 after 1.67 seconds
[0m15:52:46.897805 [debug] [MainThread]: Connection 'debug' was left open.
[0m15:52:46.898415 [debug] [MainThread]: On debug: Close
[0m15:52:46.899009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6176431f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6174df6b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60f86058e0>]}
[0m15:52:46.899657 [debug] [MainThread]: Flushing usage events
[0m15:52:52.988734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9fc150500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f95b09b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f9066990>]}


============================== 15:52:52.994756 | 17bcf77d-9d22-4664-b579-a5a342fd141e ==============================
[0m15:52:52.994756 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:52:52.995845 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/home/jovyan/dbt/workspace/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:52:53.335046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f90678f0>]}
[0m15:52:53.440364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f91003b0>]}
[0m15:52:53.441964 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:52:53.641256 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m15:52:53.851950 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m15:52:53.852903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f9aa3c50>]}
[0m15:52:57.017238 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m15:52:57.018194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f89afaa0>]}
[0m15:52:57.474318 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_rental' in the 'models' section of file 'models/marts/staging/stg_rentals.yml'
[0m15:52:57.714101 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.staging
[0m15:52:57.737985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f86c4800>]}
[0m15:52:57.950870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f8846000>]}
[0m15:52:57.951928 [info ] [MainThread]: Found 15 models, 1 snapshot, 23 data tests, 13 sources, 605 macros
[0m15:52:57.953053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f8569a30>]}
[0m15:52:57.958203 [info ] [MainThread]: 
[0m15:52:57.959417 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:52:57.971247 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:52:57.991743 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:52:58.990483 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:52:58.995409 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:52:59.026398 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:52:59.032326 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:52:59.038542 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw09_star_adw09_stag)
[0m15:52:59.049576 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_stag'
      

  ...
[0m15:52:59.092505 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m15:52:59.095005 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_stag, now list__adw09_star)
[0m15:52:59.099367 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m15:52:59.126552 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:52:59.129182 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__adw09_star_adw09_star)
[0m15:52:59.133040 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_star'
      

  ...
[0m15:52:59.158729 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:52:59.161922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff97807b560>]}
[0m15:52:59.162862 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m15:52:59.163597 [info ] [MainThread]: 
[0m15:52:59.169802 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m15:52:59.171267 [info ] [Thread-1 (]: 1 of 15 START sql view model `adw09_star_adw09_stag`.`stg_customer` ............ [RUN]
[0m15:52:59.172114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_star, now model.sakstar.stg_customer)
[0m15:52:59.172768 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m15:52:59.195294 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m15:52:59.205746 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m15:52:59.230471 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m15:52:59.248236 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m15:52:59.251525 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_star_adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.270418 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_star_adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.284384 [debug] [Thread-1 (]: Database Error in model stg_customer (models/marts/staging/stg_customer.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_customer.sql
[0m15:52:59.287041 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f9ad4fb0>]}
[0m15:52:59.288495 [error] [Thread-1 (]: 1 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_customer` ... [[31mERROR[0m in 0.11s]
[0m15:52:59.289771 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m15:52:59.290688 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer-checkpoint
[0m15:52:59.291611 [info ] [Thread-1 (]: 2 of 15 START sql view model `adw09_star_adw09_stag`.`stg_customer-checkpoint` . [RUN]
[0m15:52:59.294643 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_customer-checkpoint)
[0m15:52:59.295306 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer-checkpoint
[0m15:52:59.305012 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer-checkpoint"
[0m15:52:59.306517 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer-checkpoint
[0m15:52:59.310742 [debug] [Thread-1 (]: Creating new relation stg_customer-checkpoint
[0m15:52:59.312293 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer-checkpoint"
[0m15:52:59.313839 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer-checkpoint: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_customer-checkpoint` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.320248 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_customer-checkpoint` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.327073 [debug] [Thread-1 (]: Database Error in model stg_customer-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql
[0m15:52:59.327909 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f87629f0>]}
[0m15:52:59.328993 [error] [Thread-1 (]: 2 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_customer-checkpoint`  [[31mERROR[0m in 0.03s]
[0m15:52:59.330298 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer-checkpoint
[0m15:52:59.331186 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m15:52:59.332071 [info ] [Thread-1 (]: 3 of 15 START sql view model `adw09_star_adw09_stag`.`stg_film` ................ [RUN]
[0m15:52:59.333571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer-checkpoint, now model.sakstar.stg_film)
[0m15:52:59.334237 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m15:52:59.346083 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m15:52:59.347284 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m15:52:59.351150 [debug] [Thread-1 (]: Creating new relation stg_film
[0m15:52:59.352743 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m15:52:59.354172 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_star_adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.361309 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_star_adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.365588 [debug] [Thread-1 (]: Database Error in model stg_film (models/marts/staging/stg_film.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_film.sql
[0m15:52:59.366341 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f9ad4fb0>]}
[0m15:52:59.367401 [error] [Thread-1 (]: 3 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_film` ....... [[31mERROR[0m in 0.03s]
[0m15:52:59.368730 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m15:52:59.369467 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film-checkpoint
[0m15:52:59.370620 [info ] [Thread-1 (]: 4 of 15 START sql view model `adw09_star_adw09_stag`.`stg_film-checkpoint` ..... [RUN]
[0m15:52:59.371658 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_film-checkpoint)
[0m15:52:59.372323 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film-checkpoint
[0m15:52:59.382539 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film-checkpoint"
[0m15:52:59.384040 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film-checkpoint
[0m15:52:59.390105 [debug] [Thread-1 (]: Creating new relation stg_film-checkpoint
[0m15:52:59.392765 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film-checkpoint"
[0m15:52:59.394580 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film-checkpoint: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_film-checkpoint` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.401979 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_film-checkpoint` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.406583 [debug] [Thread-1 (]: Database Error in model stg_film-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql
[0m15:52:59.407554 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff977570350>]}
[0m15:52:59.408730 [error] [Thread-1 (]: 4 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_film-checkpoint`  [[31mERROR[0m in 0.04s]
[0m15:52:59.410053 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film-checkpoint
[0m15:52:59.410974 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m15:52:59.411811 [info ] [Thread-1 (]: 5 of 15 START sql view model `adw09_star_adw09_stag`.`stg_rentals` ............. [RUN]
[0m15:52:59.413131 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film-checkpoint, now model.sakstar.stg_rentals)
[0m15:52:59.413919 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m15:52:59.425009 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m15:52:59.426095 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m15:52:59.430128 [debug] [Thread-1 (]: Creating new relation stg_rentals
[0m15:52:59.432034 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m15:52:59.433072 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_star_adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.440143 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_star_adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.444829 [debug] [Thread-1 (]: Database Error in model stg_rentals (models/marts/staging/stg_rentals.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_rentals.sql
[0m15:52:59.445963 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9774b4680>]}
[0m15:52:59.447147 [error] [Thread-1 (]: 5 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_rentals` .... [[31mERROR[0m in 0.03s]
[0m15:52:59.448240 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m15:52:59.449017 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals-checkpoint
[0m15:52:59.449999 [info ] [Thread-1 (]: 6 of 15 START sql view model `adw09_star_adw09_stag`.`stg_rentals-checkpoint` .. [RUN]
[0m15:52:59.451381 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_rentals-checkpoint)
[0m15:52:59.452073 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals-checkpoint
[0m15:52:59.462456 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals-checkpoint"
[0m15:52:59.463620 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals-checkpoint
[0m15:52:59.467487 [debug] [Thread-1 (]: Creating new relation stg_rentals-checkpoint
[0m15:52:59.469032 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals-checkpoint"
[0m15:52:59.470175 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals-checkpoint: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_rentals-checkpoint` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.476237 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_rentals-checkpoint` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.480114 [debug] [Thread-1 (]: Database Error in model stg_rentals-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql
[0m15:52:59.480832 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff975c07b90>]}
[0m15:52:59.481974 [error] [Thread-1 (]: 6 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_rentals-checkpoint`  [[31mERROR[0m in 0.03s]
[0m15:52:59.483155 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals-checkpoint
[0m15:52:59.483926 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m15:52:59.485068 [info ] [Thread-1 (]: 7 of 15 START sql view model `adw09_star_adw09_stag`.`stg_staff` ............... [RUN]
[0m15:52:59.486148 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals-checkpoint, now model.sakstar.stg_staff)
[0m15:52:59.486964 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m15:52:59.501077 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m15:52:59.502185 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m15:52:59.634427 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m15:52:59.636473 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m15:52:59.638294 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_star_adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.646350 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_star_adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.650488 [debug] [Thread-1 (]: Database Error in model stg_staff (models/marts/staging/stg_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_staff.sql
[0m15:52:59.651366 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9774ce150>]}
[0m15:52:59.652366 [error] [Thread-1 (]: 7 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_staff` ...... [[31mERROR[0m in 0.17s]
[0m15:52:59.653750 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m15:52:59.654891 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff-checkpoint
[0m15:52:59.655778 [info ] [Thread-1 (]: 8 of 15 START sql view model `adw09_star_adw09_stag`.`stg_staff-checkpoint` .... [RUN]
[0m15:52:59.657226 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_staff-checkpoint)
[0m15:52:59.658907 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff-checkpoint
[0m15:52:59.669119 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff-checkpoint"
[0m15:52:59.670223 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff-checkpoint
[0m15:52:59.674619 [debug] [Thread-1 (]: Creating new relation stg_staff-checkpoint
[0m15:52:59.676552 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff-checkpoint"
[0m15:52:59.677678 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff-checkpoint: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_staff-checkpoint` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.683750 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_staff-checkpoint` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.687783 [debug] [Thread-1 (]: Database Error in model stg_staff-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql
[0m15:52:59.688566 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff977612f60>]}
[0m15:52:59.689653 [error] [Thread-1 (]: 8 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_staff-checkpoint`  [[31mERROR[0m in 0.03s]
[0m15:52:59.691394 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff-checkpoint
[0m15:52:59.692331 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m15:52:59.693633 [info ] [Thread-1 (]: 9 of 15 START sql view model `adw09_star_adw09_stag`.`stg_store` ............... [RUN]
[0m15:52:59.695017 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff-checkpoint, now model.sakstar.stg_store)
[0m15:52:59.695968 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m15:52:59.708514 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m15:52:59.710412 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m15:52:59.716659 [debug] [Thread-1 (]: Creating new relation stg_store
[0m15:52:59.719339 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m15:52:59.721017 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_star_adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.728042 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_star_adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.731985 [debug] [Thread-1 (]: Database Error in model stg_store (models/marts/staging/stg_store.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_store.sql
[0m15:52:59.732725 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff977586a80>]}
[0m15:52:59.733792 [error] [Thread-1 (]: 9 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_store` ...... [[31mERROR[0m in 0.04s]
[0m15:52:59.734893 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m15:52:59.735694 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store-checkpoint
[0m15:52:59.736834 [info ] [Thread-1 (]: 10 of 15 START sql view model `adw09_star_adw09_stag`.`stg_store-checkpoint` ... [RUN]
[0m15:52:59.738595 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.stg_store-checkpoint)
[0m15:52:59.739371 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store-checkpoint
[0m15:52:59.749782 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store-checkpoint"
[0m15:52:59.751034 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store-checkpoint
[0m15:52:59.755878 [debug] [Thread-1 (]: Creating new relation stg_store-checkpoint
[0m15:52:59.758727 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store-checkpoint"
[0m15:52:59.760830 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store-checkpoint: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_store-checkpoint` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:52:59.768119 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store-checkpoint"} */


  create or replace view `adw09_star_adw09_stag`.`stg_store-checkpoint` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    
[0m15:52:59.773641 [debug] [Thread-1 (]: Database Error in model stg_store-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql
[0m15:52:59.774980 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17bcf77d-9d22-4664-b579-a5a342fd141e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f882be90>]}
[0m15:52:59.776380 [error] [Thread-1 (]: 10 of 15 ERROR creating sql view model `adw09_star_adw09_stag`.`stg_store-checkpoint`  [[31mERROR[0m in 0.04s]
[0m15:52:59.777793 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store-checkpoint
[0m15:52:59.778596 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m15:52:59.779591 [info ] [Thread-1 (]: 11 of 15 SKIP relation adw09_star_adw09_star.dim_customer ...................... [[33mSKIP[0m]
[0m15:52:59.780650 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m15:52:59.781488 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m15:52:59.782172 [info ] [Thread-1 (]: 12 of 15 SKIP relation adw09_star_adw09_star.dim_film .......................... [[33mSKIP[0m]
[0m15:52:59.783224 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m15:52:59.784000 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m15:52:59.784645 [info ] [Thread-1 (]: 13 of 15 SKIP relation adw09_star_adw09_star.dim_staff ......................... [[33mSKIP[0m]
[0m15:52:59.785733 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m15:52:59.787051 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m15:52:59.788091 [info ] [Thread-1 (]: 14 of 15 SKIP relation adw09_star_adw09_star.dim_store ......................... [[33mSKIP[0m]
[0m15:52:59.790021 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m15:52:59.792172 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m15:52:59.792948 [info ] [Thread-1 (]: 15 of 15 SKIP relation adw09_star_adw09_star.fct_rentals ....................... [[33mSKIP[0m]
[0m15:52:59.793767 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m15:52:59.797063 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:52:59.797648 [debug] [MainThread]: Connection 'model.sakstar.stg_store-checkpoint' was left open.
[0m15:52:59.798146 [debug] [MainThread]: On model.sakstar.stg_store-checkpoint: Close
[0m15:52:59.799031 [info ] [MainThread]: 
[0m15:52:59.799594 [info ] [MainThread]: Finished running 10 view models, 5 incremental models in 0 hours 0 minutes and 1.84 seconds (1.84s).
[0m15:52:59.805068 [debug] [MainThread]: Command end result
[0m15:52:59.903806 [info ] [MainThread]: 
[0m15:52:59.905050 [info ] [MainThread]: [31mCompleted with 10 errors and 0 warnings:[0m
[0m15:52:59.905917 [info ] [MainThread]: 
[0m15:52:59.907080 [error] [MainThread]:   Database Error in model stg_customer (models/marts/staging/stg_customer.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_customer.sql
[0m15:52:59.908065 [info ] [MainThread]: 
[0m15:52:59.909458 [error] [MainThread]:   Database Error in model stg_customer-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql
[0m15:52:59.910765 [info ] [MainThread]: 
[0m15:52:59.912125 [error] [MainThread]:   Database Error in model stg_film (models/marts/staging/stg_film.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_film.sql
[0m15:52:59.913186 [info ] [MainThread]: 
[0m15:52:59.914432 [error] [MainThread]:   Database Error in model stg_film-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql
[0m15:52:59.915437 [info ] [MainThread]: 
[0m15:52:59.916748 [error] [MainThread]:   Database Error in model stg_rentals (models/marts/staging/stg_rentals.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_rentals.sql
[0m15:52:59.917989 [info ] [MainThread]: 
[0m15:52:59.919245 [error] [MainThread]:   Database Error in model stg_rentals-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql
[0m15:52:59.920251 [info ] [MainThread]: 
[0m15:52:59.921209 [error] [MainThread]:   Database Error in model stg_staff (models/marts/staging/stg_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_staff.sql
[0m15:52:59.922104 [info ] [MainThread]: 
[0m15:52:59.922802 [error] [MainThread]:   Database Error in model stg_staff-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql
[0m15:52:59.923473 [info ] [MainThread]: 
[0m15:52:59.924685 [error] [MainThread]:   Database Error in model stg_store (models/marts/staging/stg_store.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/stg_store.sql
[0m15:52:59.925826 [info ] [MainThread]: 
[0m15:52:59.926785 [error] [MainThread]:   Database Error in model stg_store-checkpoint (models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 81
   Code: 81. DB::Exception: Database sakila_dwh does not exist. Maybe you meant sakila_dwh2?. (UNKNOWN_DATABASE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql
[0m15:52:59.927497 [info ] [MainThread]: 
[0m15:52:59.928258 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=10 SKIP=5 TOTAL=15
[0m15:52:59.930057 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.031346, "process_in_blocks": "192", "process_kernel_time": 0.930827, "process_mem_max_rss": "209852", "process_out_blocks": "5192", "process_user_time": 10.379228}
[0m15:52:59.930752 [debug] [MainThread]: Command `dbt run` failed at 15:52:59.930583 after 7.03 seconds
[0m15:52:59.931329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f9407320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9f88308c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff9fc150500>]}
[0m15:52:59.932092 [debug] [MainThread]: Flushing usage events
[0m15:58:28.011878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888affdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8896c4890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888bfc4d0>]}


============================== 15:58:28.020073 | 5e04be75-7b88-48e1-8875-4735b07b7036 ==============================
[0m15:58:28.020073 [info ] [MainThread]: Running with dbt=1.8.9
[0m15:58:28.021660 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/home/jovyan/dbt/workspace/logs', 'profiles_dir': '/home/jovyan/dbt/workspace', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:58:28.362825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888b587a0>]}
[0m15:58:28.466935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888b58ad0>]}
[0m15:58:28.468358 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m15:58:28.660823 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m15:58:28.929819 [debug] [MainThread]: Partial parsing enabled: 5 files deleted, 0 files added, 0 files changed.
[0m15:58:28.930938 [debug] [MainThread]: Partial parsing: deleted file: sakstar://models/marts/staging/.ipynb_checkpoints/stg_film-checkpoint.sql
[0m15:58:28.931600 [debug] [MainThread]: Partial parsing: deleted file: sakstar://models/marts/staging/.ipynb_checkpoints/stg_staff-checkpoint.sql
[0m15:58:28.932255 [debug] [MainThread]: Partial parsing: deleted file: sakstar://models/marts/staging/.ipynb_checkpoints/stg_store-checkpoint.sql
[0m15:58:28.932843 [debug] [MainThread]: Partial parsing: deleted file: sakstar://models/marts/staging/.ipynb_checkpoints/stg_rentals-checkpoint.sql
[0m15:58:28.933286 [debug] [MainThread]: Partial parsing: deleted file: sakstar://models/marts/staging/.ipynb_checkpoints/stg_customer-checkpoint.sql
[0m15:58:29.092902 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.staging
[0m15:58:29.119346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888671070>]}
[0m15:58:29.347517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88843a2d0>]}
[0m15:58:29.348796 [info ] [MainThread]: Found 10 models, 1 snapshot, 23 data tests, 13 sources, 605 macros
[0m15:58:29.349501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88840b6b0>]}
[0m15:58:29.353506 [info ] [MainThread]: 
[0m15:58:29.354738 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m15:58:29.365811 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m15:58:29.389548 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:58:30.399934 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:58:30.404760 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m15:58:30.430174 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m15:58:30.436394 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:58:30.439303 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__adw09_star_adw09_stag)
[0m15:58:30.440330 [debug] [ThreadPool]: Creating schema "schema: "adw09_star_adw09_stag"
"
[0m15:58:30.455021 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_star_adw09_stag"} */
create database if not exists `adw09_star_adw09_stag`
        
  
        
  ...
[0m15:58:30.464226 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:58:30.466723 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_star_adw09_stag, now create__adw09_star_adw09_star)
[0m15:58:30.467574 [debug] [ThreadPool]: Creating schema "schema: "adw09_star_adw09_star"
"
[0m15:58:30.471777 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_star_adw09_star"} */
create database if not exists `adw09_star_adw09_star`
        
  
        
  ...
[0m15:58:30.481174 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:58:30.486017 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_star_adw09_star, now list__adw09_star)
[0m15:58:30.496608 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m15:58:30.530623 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:58:30.533637 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__adw09_star_adw09_stag)
[0m15:58:30.537440 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_stag'
      

  ...
[0m15:58:30.562186 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:58:30.564660 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_stag, now list__adw09_star_adw09_star)
[0m15:58:30.568632 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_star'
      

  ...
[0m15:58:30.593571 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:58:30.596709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8076121b0>]}
[0m15:58:30.598092 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m15:58:30.599018 [info ] [MainThread]: 
[0m15:58:30.604707 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m15:58:30.605890 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_star_adw09_stag`.`stg_customer` ............ [RUN]
[0m15:58:30.606871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_star, now model.sakstar.stg_customer)
[0m15:58:30.607522 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m15:58:30.653827 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m15:58:30.655154 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m15:58:30.688863 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m15:58:30.704456 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m15:58:30.705777 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_star_adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:58:30.736950 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:58:30.774584 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88a2e3ec0>]}
[0m15:58:30.775802 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_customer` ....... [[32mOK[0m in 0.17s]
[0m15:58:30.776960 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m15:58:30.777732 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m15:58:30.779166 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_star_adw09_stag`.`stg_film` ................ [RUN]
[0m15:58:30.780214 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m15:58:30.780837 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m15:58:30.792512 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m15:58:30.793720 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m15:58:30.797325 [debug] [Thread-1 (]: Creating new relation stg_film
[0m15:58:30.799194 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m15:58:30.800700 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_star_adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:58:30.834728 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:58:30.839081 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8070b73e0>]}
[0m15:58:30.840626 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_film` ........... [[32mOK[0m in 0.06s]
[0m15:58:30.841846 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m15:58:30.842702 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m15:58:30.843655 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_star_adw09_stag`.`stg_rentals` ............. [RUN]
[0m15:58:30.846194 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m15:58:30.846945 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m15:58:30.862292 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m15:58:30.864059 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m15:58:30.871998 [debug] [Thread-1 (]: Creating new relation stg_rentals
[0m15:58:30.874400 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m15:58:30.875916 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_star_adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:58:30.921098 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m15:58:30.926493 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8070ed910>]}
[0m15:58:30.928569 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_rentals` ........ [[32mOK[0m in 0.08s]
[0m15:58:30.931341 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m15:58:30.933123 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m15:58:30.934475 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_star_adw09_stag`.`stg_staff` ............... [RUN]
[0m15:58:30.935871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m15:58:30.936593 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m15:58:30.946882 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m15:58:30.948275 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m15:58:30.952719 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m15:58:30.954509 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m15:58:30.955708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_star_adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:58:30.980350 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:58:30.984915 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb807123d70>]}
[0m15:58:30.986286 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_staff` .......... [[32mOK[0m in 0.05s]
[0m15:58:30.987558 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m15:58:30.988323 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m15:58:30.989225 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_star_adw09_stag`.`stg_store` ............... [RUN]
[0m15:58:30.990674 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m15:58:30.991518 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m15:58:31.002108 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m15:58:31.003544 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m15:58:31.008233 [debug] [Thread-1 (]: Creating new relation stg_store
[0m15:58:31.009962 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m15:58:31.011135 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_star_adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m15:58:31.042405 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:58:31.048516 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80578aea0>]}
[0m15:58:31.050082 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_store` .......... [[32mOK[0m in 0.06s]
[0m15:58:31.051518 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m15:58:31.052712 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m15:58:31.053739 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_customer` ..... [RUN]
[0m15:58:31.055406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m15:58:31.056317 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m15:58:31.070382 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m15:58:31.072413 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m15:58:31.213389 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star_adw09_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_star_adw09_stag`.`stg_customer`


          )
        
        ...
[0m15:58:31.240060 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:58:31.274854 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star_adw09_star'
    
    order by position
  ...
[0m15:58:31.282400 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:58:31.291078 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m15:58:31.293338 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star_adw09_star`.`dim_customer`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_star_adw09_stag`.`stg_customer`


  
    ...
[0m15:58:31.429596 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.14 seconds
[0m15:58:31.441645 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb80718b8c0>]}
[0m15:58:31.442959 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star_adw09_star`.`dim_customer`  [[32mOK[0m in 0.39s]
[0m15:58:31.444279 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m15:58:31.445102 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m15:58:31.445944 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_film` ......... [RUN]
[0m15:58:31.447073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m15:58:31.447708 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m15:58:31.456866 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m15:58:31.458540 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m15:58:31.467356 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star_adw09_star`.`dim_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_star_adw09_stag`.`stg_film`


          )
        
        ...
[0m15:58:31.493842 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m15:58:31.502042 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star_adw09_star'
    
    order by position
  ...
[0m15:58:31.509606 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:58:31.515656 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m15:58:31.517826 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star_adw09_star`.`dim_film`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_star_adw09_stag`.`stg_film`


  
    ...
[0m15:58:31.680046 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.16 seconds
[0m15:58:31.684057 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8057d38c0>]}
[0m15:58:31.685295 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star_adw09_star`.`dim_film` .... [[32mOK[0m in 0.24s]
[0m15:58:31.686541 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m15:58:31.687544 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m15:58:31.688827 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_staff` ........ [RUN]
[0m15:58:31.689652 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m15:58:31.690561 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m15:58:31.697281 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m15:58:31.699689 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m15:58:31.708781 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star_adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `adw09_star_adw09_stag`.`stg_staff`


          )
        
        ...
[0m15:58:31.718216 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star_adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `adw09_star_adw09_stag`.`stg_staff`


          )
        
        
[0m15:58:31.727938 [debug] [Thread-1 (]: Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `staff_store_id` in scope SELECT staff_skey, staff_id, staff_first_name, staff_last_name, staff_email, staff_store_id, staff_active, staff_last_update FROM adw09_star_adw09_stag.stg_staff. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m15:58:31.729023 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8072284d0>]}
[0m15:58:31.730316 [error] [Thread-1 (]: 8 of 10 ERROR creating sql incremental model `adw09_star_adw09_star`.`dim_staff`  [[31mERROR[0m in 0.04s]
[0m15:58:31.731957 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m15:58:31.733226 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m15:58:31.734395 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_store` ........ [RUN]
[0m15:58:31.736943 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m15:58:31.737759 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m15:58:31.744650 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m15:58:31.746372 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m15:58:31.754718 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star_adw09_star`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_star_adw09_stag`.`stg_store`


          )
        
        ...
[0m15:58:31.774757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m15:58:31.780603 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star_adw09_star'
    
    order by position
  ...
[0m15:58:31.789469 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m15:58:31.794579 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m15:58:31.796405 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star_adw09_star`.`dim_store`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_star_adw09_stag`.`stg_store`


  
    ...
[0m15:58:31.954875 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.16 seconds
[0m15:58:31.960881 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e04be75-7b88-48e1-8875-4735b07b7036', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb805817a10>]}
[0m15:58:31.962859 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star_adw09_star`.`dim_store` ... [[32mOK[0m in 0.22s]
[0m15:58:31.965711 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m15:58:31.968713 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m15:58:31.970038 [info ] [Thread-1 (]: 10 of 10 SKIP relation adw09_star_adw09_star.fct_rentals ....................... [[33mSKIP[0m]
[0m15:58:31.971248 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m15:58:31.974999 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:58:31.975721 [debug] [MainThread]: Connection 'model.sakstar.dim_store' was left open.
[0m15:58:31.976351 [debug] [MainThread]: On model.sakstar.dim_store: Close
[0m15:58:31.977349 [info ] [MainThread]: 
[0m15:58:31.978181 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 2.62 seconds (2.62s).
[0m15:58:31.981471 [debug] [MainThread]: Command end result
[0m15:58:32.057103 [info ] [MainThread]: 
[0m15:58:32.058073 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:58:32.058737 [info ] [MainThread]: 
[0m15:58:32.059611 [error] [MainThread]:   Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `staff_store_id` in scope SELECT staff_skey, staff_id, staff_first_name, staff_last_name, staff_email, staff_store_id, staff_active, staff_last_update FROM adw09_star_adw09_stag.stg_staff. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m15:58:32.060577 [info ] [MainThread]: 
[0m15:58:32.061290 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=1 TOTAL=10
[0m15:58:32.063304 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.140095, "process_in_blocks": "0", "process_kernel_time": 1.223114, "process_mem_max_rss": "209216", "process_out_blocks": "4984", "process_user_time": 6.63266}
[0m15:58:32.064258 [debug] [MainThread]: Command `dbt run` failed at 15:58:32.064034 after 4.14 seconds
[0m15:58:32.065061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88949d700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888701670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb888b5b260>]}
[0m15:58:32.065982 [debug] [MainThread]: Flushing usage events
[0m16:00:48.398572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc22fbd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc22fa780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc22fbe90>]}


============================== 16:00:48.404663 | a24fa518-fca8-4e61-bd15-00759359e951 ==============================
[0m16:00:48.404663 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:00:48.405606 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/home/jovyan/dbt/workspace/logs', 'fail_fast': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:00:48.740826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc34dc7d0>]}
[0m16:00:48.845661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc26f73b0>]}
[0m16:00:48.847483 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:00:49.015151 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:00:49.233477 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m16:00:49.234323 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc1b95d00>]}
[0m16:00:52.308902 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:00:52.309805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc19dcd40>]}
[0m16:00:52.767859 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_rental' in the 'models' section of file 'models/marts/staging/stg_rentals.yml'
[0m16:00:53.075056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc17849b0>]}
[0m16:00:53.322945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc179cd10>]}
[0m16:00:53.323804 [info ] [MainThread]: Found 10 models, 1 snapshot, 23 data tests, 13 sources, 605 macros
[0m16:00:53.324499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc166ac90>]}
[0m16:00:53.330321 [info ] [MainThread]: 
[0m16:00:53.331598 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:00:53.344452 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:00:53.373384 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:00:54.339802 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:00:54.344849 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:00:54.377864 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:00:54.384460 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:00:54.387806 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__adw09_star_adw09_star)
[0m16:00:54.388811 [debug] [ThreadPool]: Creating schema "schema: "adw09_star_adw09_star"
"
[0m16:00:54.402592 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_star_adw09_star"} */
create database if not exists `adw09_star_adw09_star`
        
  
        
  ...
[0m16:00:54.412853 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:00:54.415162 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_star_adw09_star, now create__adw09_star_adw09_stag)
[0m16:00:54.416052 [debug] [ThreadPool]: Creating schema "schema: "adw09_star_adw09_stag"
"
[0m16:00:54.420663 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_star_adw09_stag"} */
create database if not exists `adw09_star_adw09_stag`
        
  
        
  ...
[0m16:00:54.431180 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:00:54.436484 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_star_adw09_stag, now list__adw09_star_adw09_star)
[0m16:00:54.448903 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_star'
      

  ...
[0m16:00:54.477458 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:00:54.480238 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_star, now list__adw09_star)
[0m16:00:54.484752 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:00:54.510226 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:00:54.513528 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__adw09_star_adw09_stag)
[0m16:00:54.521060 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star_adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star_adw09_stag'
      

  ...
[0m16:00:54.547578 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:00:54.550658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc1955ac0>]}
[0m16:00:54.551947 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:00:54.552817 [info ] [MainThread]: 
[0m16:00:54.558189 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:00:54.559167 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_star_adw09_stag`.`stg_customer` ............ [RUN]
[0m16:00:54.560225 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_star_adw09_stag, now model.sakstar.stg_customer)
[0m16:00:54.560859 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:00:54.581078 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:00:54.582440 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:00:54.607898 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m16:00:54.623395 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:00:54.624952 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_star_adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:00:54.658502 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:00:54.694335 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc3a8bcb0>]}
[0m16:00:54.695670 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_customer` ....... [[32mOK[0m in 0.13s]
[0m16:00:54.697062 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:00:54.698031 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:00:54.698924 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_star_adw09_stag`.`stg_film` ................ [RUN]
[0m16:00:54.700609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:00:54.701321 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:00:54.710770 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:00:54.711980 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:00:54.717298 [debug] [Thread-1 (]: Creating new relation stg_film
[0m16:00:54.719393 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:00:54.720805 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_star_adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:00:54.752226 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:00:54.755887 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f408299d0>]}
[0m16:00:54.757157 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_film` ........... [[32mOK[0m in 0.06s]
[0m16:00:54.758308 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:00:54.759162 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:00:54.760127 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_star_adw09_stag`.`stg_rentals` ............. [RUN]
[0m16:00:54.761257 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:00:54.761883 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:00:54.774230 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:00:54.775436 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:00:54.780499 [debug] [Thread-1 (]: Creating new relation stg_rentals
[0m16:00:54.784762 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:00:54.785973 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_star_adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:00:54.810207 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:00:54.813976 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f40698e30>]}
[0m16:00:54.815097 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_rentals` ........ [[32mOK[0m in 0.05s]
[0m16:00:54.816263 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:00:54.817236 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:00:54.818213 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_star_adw09_stag`.`stg_staff` ............... [RUN]
[0m16:00:54.819502 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:00:54.820383 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:00:54.830689 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:00:54.832981 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:00:54.837988 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m16:00:54.839970 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:00:54.841592 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_star_adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:00:54.869606 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:00:54.873617 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f40657c80>]}
[0m16:00:54.874601 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_staff` .......... [[32mOK[0m in 0.05s]
[0m16:00:54.875716 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:00:54.876472 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:00:54.877290 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_star_adw09_stag`.`stg_store` ............... [RUN]
[0m16:00:54.878150 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:00:54.878916 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:00:54.890739 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:00:54.891982 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:00:54.895955 [debug] [Thread-1 (]: Creating new relation stg_store
[0m16:00:54.898330 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:00:54.899870 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_star_adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:00:54.933654 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:00:54.937099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f4069a000>]}
[0m16:00:54.938290 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_star_adw09_stag`.`stg_store` .......... [[32mOK[0m in 0.06s]
[0m16:00:54.939525 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:00:54.940448 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:00:54.941340 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_customer` ..... [RUN]
[0m16:00:54.942333 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:00:54.943111 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:00:54.950707 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:00:54.952645 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:00:55.096181 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star_adw09_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_star_adw09_stag`.`stg_customer`


          )
        
        ...
[0m16:00:55.117398 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:00:55.281108 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star_adw09_star'
    
    order by position
  ...
[0m16:00:55.288845 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:00:55.298838 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:00:55.300264 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star_adw09_star`.`dim_customer`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_star_adw09_stag`.`stg_customer`


  
    ...
[0m16:00:55.429178 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.13 seconds
[0m16:00:55.438686 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f406c84d0>]}
[0m16:00:55.439789 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star_adw09_star`.`dim_customer`  [[32mOK[0m in 0.50s]
[0m16:00:55.441105 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:00:55.441848 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:00:55.443524 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_film` ......... [RUN]
[0m16:00:55.444715 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:00:55.445660 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:00:55.452777 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:00:55.453800 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:00:55.461643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star_adw09_star`.`dim_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_star_adw09_stag`.`stg_film`


          )
        
        ...
[0m16:00:55.482971 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:00:55.488273 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star_adw09_star'
    
    order by position
  ...
[0m16:00:55.495360 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:00:55.500937 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:00:55.502105 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star_adw09_star`.`dim_film`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_star_adw09_stag`.`stg_film`


  
    ...
[0m16:00:55.655403 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:00:55.659217 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f40b67800>]}
[0m16:00:55.660556 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star_adw09_star`.`dim_film` .... [[32mOK[0m in 0.21s]
[0m16:00:55.661707 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:00:55.662825 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:00:55.664093 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_staff` ........ [RUN]
[0m16:00:55.665236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:00:55.665855 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:00:55.672881 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:00:55.674149 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:00:55.682427 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star_adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `adw09_star_adw09_stag`.`stg_staff`


          )
        
        ...
[0m16:00:55.688645 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star_adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `adw09_star_adw09_stag`.`stg_staff`


          )
        
        
[0m16:00:55.697808 [debug] [Thread-1 (]: Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `staff_store_id` in scope SELECT staff_skey, staff_id, staff_first_name, staff_last_name, staff_email, staff_store_id, staff_active, staff_last_update FROM adw09_star_adw09_stag.stg_staff. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m16:00:55.698847 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f406531a0>]}
[0m16:00:55.700130 [error] [Thread-1 (]: 8 of 10 ERROR creating sql incremental model `adw09_star_adw09_star`.`dim_staff`  [[31mERROR[0m in 0.03s]
[0m16:00:55.701347 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:00:55.702104 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:00:55.703099 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star_adw09_star`.`dim_store` ........ [RUN]
[0m16:00:55.704070 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:00:55.704781 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:00:55.713619 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:00:55.714902 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:00:55.725464 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star_adw09_star`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_star_adw09_stag`.`stg_store`


          )
        
        ...
[0m16:00:55.744792 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:00:55.753053 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star_adw09_star'
    
    order by position
  ...
[0m16:00:55.761153 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:00:55.766558 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:00:55.767917 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star_adw09_star`.`dim_store`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_star_adw09_stag`.`stg_store`


  
    ...
[0m16:00:55.913482 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.14 seconds
[0m16:00:55.917518 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a24fa518-fca8-4e61-bd15-00759359e951', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f40695b20>]}
[0m16:00:55.918605 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star_adw09_star`.`dim_store` ... [[32mOK[0m in 0.21s]
[0m16:00:55.920075 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:00:55.921753 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:00:55.923011 [info ] [Thread-1 (]: 10 of 10 SKIP relation adw09_star_adw09_star.fct_rentals ....................... [[33mSKIP[0m]
[0m16:00:55.923927 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:00:55.926957 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:55.927613 [debug] [MainThread]: Connection 'model.sakstar.dim_store' was left open.
[0m16:00:55.928477 [debug] [MainThread]: On model.sakstar.dim_store: Close
[0m16:00:55.929898 [info ] [MainThread]: 
[0m16:00:55.930661 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 2.60 seconds (2.60s).
[0m16:00:55.933849 [debug] [MainThread]: Command end result
[0m16:00:56.010302 [info ] [MainThread]: 
[0m16:00:56.011319 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:00:56.012020 [info ] [MainThread]: 
[0m16:00:56.013540 [error] [MainThread]:   Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `staff_store_id` in scope SELECT staff_skey, staff_id, staff_first_name, staff_last_name, staff_email, staff_store_id, staff_active, staff_last_update FROM adw09_star_adw09_stag.stg_staff. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m16:00:56.014494 [info ] [MainThread]: 
[0m16:00:56.015391 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=1 TOTAL=10
[0m16:00:56.017435 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.7192593, "process_in_blocks": "0", "process_kernel_time": 1.090845, "process_mem_max_rss": "208960", "process_out_blocks": "4944", "process_user_time": 10.428085}
[0m16:00:56.018576 [debug] [MainThread]: Command `dbt run` failed at 16:00:56.018257 after 7.72 seconds
[0m16:00:56.019592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc60daf30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6f412829c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fc22fbe90>]}
[0m16:00:56.020489 [debug] [MainThread]: Flushing usage events
[0m16:02:18.404442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2d166840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2f89e1b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2d167e60>]}


============================== 16:02:18.410312 | 5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c ==============================
[0m16:02:18.410312 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:02:18.411411 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'debug': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:02:18.761069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2cf3a3f0>]}
[0m16:02:18.871569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2cd83c80>]}
[0m16:02:18.873077 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:02:19.058537 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:02:19.284895 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:02:19.286220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2dbdc0e0>]}
[0m16:02:22.300631 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:02:22.301854 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2c82c650>]}
[0m16:02:22.765997 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_rental' in the 'models' section of file 'models/marts/staging/stg_rentals.yml'
[0m16:02:23.037900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2c61a5a0>]}
[0m16:02:23.253482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2e68df70>]}
[0m16:02:23.254361 [info ] [MainThread]: Found 10 models, 1 snapshot, 23 data tests, 13 sources, 605 macros
[0m16:02:23.255012 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2c5181d0>]}
[0m16:02:23.259297 [info ] [MainThread]: 
[0m16:02:23.260507 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:02:23.273179 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:02:23.291781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:02:24.239743 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:02:24.245111 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:02:24.275511 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:02:24.281258 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:02:24.284555 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__default_adw09_star)
[0m16:02:24.285449 [debug] [ThreadPool]: Creating schema "schema: "default_adw09_star"
"
[0m16:02:24.298043 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__default_adw09_star"} */
create database if not exists `default_adw09_star`
        
  
        
  ...
[0m16:02:24.307291 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:02:24.309644 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_adw09_star, now create__default_adw09_stag)
[0m16:02:24.310793 [debug] [ThreadPool]: Creating schema "schema: "default_adw09_stag"
"
[0m16:02:24.315091 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__default_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__default_adw09_stag"} */
create database if not exists `default_adw09_stag`
        
  
        
  ...
[0m16:02:24.323674 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:02:24.330002 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__default_adw09_stag, now list__adw09_star)
[0m16:02:24.342259 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:02:24.377268 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:02:24.380839 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__default_adw09_star)
[0m16:02:24.385440 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__default_adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_adw09_star'
      

  ...
[0m16:02:24.412469 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:02:24.415195 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__default_adw09_star, now list__default_adw09_stag)
[0m16:02:24.421465 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__default_adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__default_adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'default_adw09_stag'
      

  ...
[0m16:02:24.449422 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:02:24.452639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab9e7320>]}
[0m16:02:24.453706 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:02:24.454532 [info ] [MainThread]: 
[0m16:02:24.460733 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:02:24.461874 [info ] [Thread-1 (]: 1 of 10 START sql view model `default_adw09_stag`.`stg_customer` ............... [RUN]
[0m16:02:24.462958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__default_adw09_stag, now model.sakstar.stg_customer)
[0m16:02:24.463814 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:02:24.483615 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:02:24.485073 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:02:24.522247 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m16:02:24.544029 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:02:24.546680 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `default_adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:02:24.580312 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:02:24.635215 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2e8f7bc0>]}
[0m16:02:24.636731 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `default_adw09_stag`.`stg_customer` .......... [[32mOK[0m in 0.17s]
[0m16:02:24.638453 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:02:24.639470 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:02:24.640840 [info ] [Thread-1 (]: 2 of 10 START sql view model `default_adw09_stag`.`stg_film` ................... [RUN]
[0m16:02:24.642510 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:02:24.643582 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:02:24.654709 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:02:24.656237 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:02:24.662346 [debug] [Thread-1 (]: Creating new relation stg_film
[0m16:02:24.664245 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:02:24.665826 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `default_adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:02:24.703000 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m16:02:24.707209 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab67dcd0>]}
[0m16:02:24.708528 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `default_adw09_stag`.`stg_film` .............. [[32mOK[0m in 0.06s]
[0m16:02:24.709842 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:02:24.711129 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:02:24.712920 [info ] [Thread-1 (]: 3 of 10 START sql view model `default_adw09_stag`.`stg_rentals` ................ [RUN]
[0m16:02:24.714875 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:02:24.715738 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:02:24.727722 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:02:24.729219 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:02:24.734419 [debug] [Thread-1 (]: Creating new relation stg_rentals
[0m16:02:24.738956 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:02:24.740374 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `default_adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:02:24.765792 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:02:24.769446 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab4ed700>]}
[0m16:02:24.771094 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `default_adw09_stag`.`stg_rentals` ........... [[32mOK[0m in 0.05s]
[0m16:02:24.772365 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:02:24.773331 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:02:24.774543 [info ] [Thread-1 (]: 4 of 10 START sql view model `default_adw09_stag`.`stg_staff` .................. [RUN]
[0m16:02:24.775840 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:02:24.776540 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:02:24.790417 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:02:24.791726 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:02:24.797892 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m16:02:24.800649 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:02:24.802173 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `default_adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:02:24.832073 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:02:24.836433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab4efa10>]}
[0m16:02:24.837628 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `default_adw09_stag`.`stg_staff` ............. [[32mOK[0m in 0.06s]
[0m16:02:24.839192 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:02:24.840406 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:02:24.842150 [info ] [Thread-1 (]: 5 of 10 START sql view model `default_adw09_stag`.`stg_store` .................. [RUN]
[0m16:02:24.843342 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:02:24.844013 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:02:24.855467 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:02:24.856745 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:02:24.861612 [debug] [Thread-1 (]: Creating new relation stg_store
[0m16:02:24.863688 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:02:24.865392 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `default_adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:02:24.900220 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:02:24.904241 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab4ebcb0>]}
[0m16:02:24.905707 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `default_adw09_stag`.`stg_store` ............. [[32mOK[0m in 0.06s]
[0m16:02:24.906984 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:02:24.908019 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:02:24.908972 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `default_adw09_star`.`dim_customer` ........ [RUN]
[0m16:02:24.910035 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:02:24.910987 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:02:24.920475 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:02:24.921736 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:02:25.082597 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `default_adw09_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `default_adw09_stag`.`stg_customer`


          )
        
        ...
[0m16:02:25.108243 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:02:25.289777 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'default_adw09_star'
    
    order by position
  ...
[0m16:02:25.298768 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:02:25.308750 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:02:25.310456 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `default_adw09_star`.`dim_customer`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `default_adw09_stag`.`stg_customer`


  
    ...
[0m16:02:25.444868 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.13 seconds
[0m16:02:25.454599 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab502690>]}
[0m16:02:25.455792 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `default_adw09_star`.`dim_customer` ... [[32mOK[0m in 0.54s]
[0m16:02:25.456969 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:02:25.457684 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:02:25.458526 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `default_adw09_star`.`dim_film` ............ [RUN]
[0m16:02:25.459444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:02:25.460779 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:02:25.467635 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:02:25.468825 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:02:25.475450 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `default_adw09_star`.`dim_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `default_adw09_stag`.`stg_film`


          )
        
        ...
[0m16:02:25.496768 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:02:25.502781 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'default_adw09_star'
    
    order by position
  ...
[0m16:02:25.509890 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:02:25.516352 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:02:25.517629 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `default_adw09_star`.`dim_film`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `default_adw09_stag`.`stg_film`


  
    ...
[0m16:02:25.676142 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.16 seconds
[0m16:02:25.680637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3daba72a50>]}
[0m16:02:25.681985 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `default_adw09_star`.`dim_film` ....... [[32mOK[0m in 0.22s]
[0m16:02:25.683177 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:02:25.683958 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:02:25.684751 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `default_adw09_star`.`dim_staff` ........... [RUN]
[0m16:02:25.686023 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:02:25.686693 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:02:25.693500 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:02:25.694765 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:02:25.702127 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `default_adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `default_adw09_stag`.`stg_staff`


          )
        
        ...
[0m16:02:25.707711 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `default_adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `default_adw09_stag`.`stg_staff`


          )
        
        
[0m16:02:25.718043 [debug] [Thread-1 (]: Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `staff_store_id` in scope SELECT staff_skey, staff_id, staff_first_name, staff_last_name, staff_email, staff_store_id, staff_active, staff_last_update FROM default_adw09_stag.stg_staff. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m16:02:25.719359 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab4ecd40>]}
[0m16:02:25.720713 [error] [Thread-1 (]: 8 of 10 ERROR creating sql incremental model `default_adw09_star`.`dim_staff` .. [[31mERROR[0m in 0.03s]
[0m16:02:25.721883 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:02:25.722740 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:02:25.723655 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `default_adw09_star`.`dim_store` ........... [RUN]
[0m16:02:25.724796 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:02:25.725719 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:02:25.735684 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:02:25.736909 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:02:25.748063 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `default_adw09_star`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `default_adw09_stag`.`stg_store`


          )
        
        ...
[0m16:02:25.767063 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:02:25.773017 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'default_adw09_star'
    
    order by position
  ...
[0m16:02:25.780421 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:02:25.784913 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:02:25.786054 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `default_adw09_star`.`dim_store`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `default_adw09_stag`.`stg_store`


  
    ...
[0m16:02:25.936179 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:02:25.939958 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a1bff07-f602-4b0b-a2a8-ef6acbb0b15c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dab4efa40>]}
[0m16:02:25.941006 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `default_adw09_star`.`dim_store` ...... [[32mOK[0m in 0.22s]
[0m16:02:25.942365 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:02:25.944576 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:02:25.945422 [info ] [Thread-1 (]: 10 of 10 SKIP relation default_adw09_star.fct_rentals .......................... [[33mSKIP[0m]
[0m16:02:25.946475 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:02:25.949208 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:02:25.949830 [debug] [MainThread]: Connection 'model.sakstar.dim_store' was left open.
[0m16:02:25.950410 [debug] [MainThread]: On model.sakstar.dim_store: Close
[0m16:02:25.951216 [info ] [MainThread]: 
[0m16:02:25.951859 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 2.69 seconds (2.69s).
[0m16:02:25.955162 [debug] [MainThread]: Command end result
[0m16:02:26.033191 [info ] [MainThread]: 
[0m16:02:26.034306 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:02:26.035042 [info ] [MainThread]: 
[0m16:02:26.035840 [error] [MainThread]:   Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `staff_store_id` in scope SELECT staff_skey, staff_id, staff_first_name, staff_last_name, staff_email, staff_store_id, staff_active, staff_last_update FROM default_adw09_stag.stg_staff. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m16:02:26.036561 [info ] [MainThread]: 
[0m16:02:26.037267 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=1 TOTAL=10
[0m16:02:26.039195 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.722448, "process_in_blocks": "48", "process_kernel_time": 1.172603, "process_mem_max_rss": "212228", "process_out_blocks": "4944", "process_user_time": 10.322917}
[0m16:02:26.040045 [debug] [MainThread]: Command `dbt run` failed at 16:02:26.039727 after 7.72 seconds
[0m16:02:26.040677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2cf10860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3e2cf10a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dac2ba300>]}
[0m16:02:26.041288 [debug] [MainThread]: Flushing usage events
[0m16:06:09.385539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f676fa3b0e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f677111b8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f676fa38e90>]}


============================== 16:06:09.392051 | 30792031-34bb-423d-b5bb-d1496e447f83 ==============================
[0m16:06:09.392051 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:06:09.393367 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/home/jovyan/dbt/workspace/logs', 'fail_fast': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:06:09.407311 [info ] [MainThread]: dbt version: 1.8.9
[0m16:06:09.408193 [info ] [MainThread]: python version: 3.12.9
[0m16:06:09.408898 [info ] [MainThread]: python path: /opt/conda/bin/python3.12
[0m16:06:09.409556 [info ] [MainThread]: os info: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.39
[0m16:06:09.538779 [info ] [MainThread]: Using profiles dir at /home/jovyan/dbt/workspace
[0m16:06:09.539682 [info ] [MainThread]: Using profiles.yml file at /home/jovyan/dbt/workspace/profiles.yml
[0m16:06:09.540682 [info ] [MainThread]: Using dbt_project.yml file at /home/jovyan/dbt/workspace/dbt_project.yml
[0m16:06:09.542064 [info ] [MainThread]: adapter type: clickhouse
[0m16:06:09.542653 [info ] [MainThread]: adapter version: 1.8.9
[0m16:06:09.718921 [info ] [MainThread]: Configuration:
[0m16:06:09.719945 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m16:06:09.720643 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m16:06:09.721220 [info ] [MainThread]: Required dependencies:
[0m16:06:09.721797 [debug] [MainThread]: Executing "git --help"
[0m16:06:09.726195 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--config-env=<name>=<envvar>] <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m16:06:09.727149 [debug] [MainThread]: STDERR: "b''"
[0m16:06:09.727656 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m16:06:09.728279 [info ] [MainThread]: Connection:
[0m16:06:09.729303 [info ] [MainThread]:   driver: None
[0m16:06:09.730064 [info ] [MainThread]:   host: clickhouse
[0m16:06:09.730638 [info ] [MainThread]:   port: 8123
[0m16:06:09.731314 [info ] [MainThread]:   user: usuario_sak
[0m16:06:09.732055 [info ] [MainThread]:   schema: adw09
[0m16:06:09.732615 [info ] [MainThread]:   retries: 1
[0m16:06:09.733223 [info ] [MainThread]:   database_engine: None
[0m16:06:09.733863 [info ] [MainThread]:   cluster_mode: False
[0m16:06:09.734453 [info ] [MainThread]:   secure: False
[0m16:06:09.735119 [info ] [MainThread]:   verify: True
[0m16:06:09.735696 [info ] [MainThread]:   client_cert: None
[0m16:06:09.736394 [info ] [MainThread]:   client_cert_key: None
[0m16:06:09.737028 [info ] [MainThread]:   connect_timeout: 10
[0m16:06:09.737626 [info ] [MainThread]:   send_receive_timeout: 300
[0m16:06:09.738235 [info ] [MainThread]:   sync_request_timeout: 5
[0m16:06:09.738779 [info ] [MainThread]:   compress_block_size: 1048576
[0m16:06:09.739522 [info ] [MainThread]:   compression: 
[0m16:06:09.740326 [info ] [MainThread]:   check_exchange: True
[0m16:06:09.741235 [info ] [MainThread]:   custom_settings: None
[0m16:06:09.741793 [info ] [MainThread]:   use_lw_deletes: False
[0m16:06:09.742501 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m16:06:09.743191 [info ] [MainThread]:   tcp_keepalive: False
[0m16:06:09.744124 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:06:09.881577 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m16:06:09.882741 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:06:10.857368 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m16:06:10.864599 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:10.895522 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m16:06:10.896437 [info ] [MainThread]: [32mAll checks passed![0m
[0m16:06:10.898421 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 1.6009917, "process_in_blocks": "0", "process_kernel_time": 1.157878, "process_mem_max_rss": "195940", "process_out_blocks": "32", "process_user_time": 4.853021}
[0m16:06:10.899171 [debug] [MainThread]: Command `dbt debug` succeeded at 16:06:10.898999 after 1.60 seconds
[0m16:06:10.899958 [debug] [MainThread]: Connection 'debug' was left open.
[0m16:06:10.900516 [debug] [MainThread]: On debug: Close
[0m16:06:10.901176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f677004dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f676f32b6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f66f35428a0>]}
[0m16:06:10.901821 [debug] [MainThread]: Flushing usage events
[0m16:06:16.452633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0bc1fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0ce00920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0c260bc0>]}


============================== 16:06:16.458179 | 6b5b9db1-f28f-41f1-9657-3a5ddc126c76 ==============================
[0m16:06:16.458179 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:06:16.459733 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:06:16.792400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0b89e810>]}
[0m16:06:16.897663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0b8c7110>]}
[0m16:06:16.899103 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:06:17.061428 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:06:17.263222 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:06:17.264019 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m16:06:17.264674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0c65f950>]}
[0m16:06:20.296262 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:06:20.297230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0b47d460>]}
[0m16:06:20.877682 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_rental' in the 'models' section of file 'models/marts/staging/stg_rentals.yml'
[0m16:06:21.082886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0b0128d0>]}
[0m16:06:21.292095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0b1ca570>]}
[0m16:06:21.293105 [info ] [MainThread]: Found 10 models, 1 snapshot, 23 data tests, 13 sources, 605 macros
[0m16:06:21.293878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0b19ed80>]}
[0m16:06:21.298423 [info ] [MainThread]: 
[0m16:06:21.299501 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:06:21.310641 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:06:21.329045 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:06:22.322501 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:06:22.328521 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:22.359903 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:06:22.365722 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:06:22.368951 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__adw09_stag)
[0m16:06:22.369983 [debug] [ThreadPool]: Creating schema "schema: "adw09_stag"
"
[0m16:06:22.382510 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_stag"} */
create database if not exists `adw09_stag`
        
  
        
  ...
[0m16:06:22.392456 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:22.397466 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_stag, now list__adw09_stag)
[0m16:06:22.408763 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_stag'
      

  ...
[0m16:06:22.439397 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.442550 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_stag, now list__adw09_star)
[0m16:06:22.446526 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:06:22.472830 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.476088 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__star)
[0m16:06:22.480342 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'star'
      

  ...
[0m16:06:22.507966 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.514297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0d22cb30>]}
[0m16:06:22.515466 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:06:22.516224 [info ] [MainThread]: 
[0m16:06:22.521432 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:06:22.522738 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_stag`.`stg_customer` ....................... [RUN]
[0m16:06:22.523774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__star, now model.sakstar.stg_customer)
[0m16:06:22.524468 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:06:22.541862 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:06:22.543242 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:06:22.577316 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m16:06:22.593348 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:06:22.595066 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:06:22.628343 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.665898 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0d38fc20>]}
[0m16:06:22.667211 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_stag`.`stg_customer` .................. [[32mOK[0m in 0.14s]
[0m16:06:22.668669 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:06:22.669723 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:06:22.670771 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_stag`.`stg_film` ........................... [RUN]
[0m16:06:22.671807 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:06:22.672474 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:06:22.683618 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:06:22.685148 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:06:22.689429 [debug] [Thread-1 (]: Creating new relation stg_film
[0m16:06:22.691481 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:06:22.692978 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:06:22.728657 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.732777 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d8a09d1f0>]}
[0m16:06:22.734169 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m16:06:22.735558 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:06:22.736512 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:06:22.737514 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_stag`.`stg_rentals` ........................ [RUN]
[0m16:06:22.738595 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:06:22.739999 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:06:22.751133 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:06:22.752360 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:06:22.756482 [debug] [Thread-1 (]: Creating new relation stg_rentals
[0m16:06:22.760467 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:06:22.762630 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:06:22.789166 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.793897 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d89fce5d0>]}
[0m16:06:22.795233 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_stag`.`stg_rentals` ................... [[32mOK[0m in 0.06s]
[0m16:06:22.796629 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:06:22.797662 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:06:22.799205 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_stag`.`stg_staff` .......................... [RUN]
[0m16:06:22.800452 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:06:22.801120 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:06:22.814358 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:06:22.815650 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:06:22.820784 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m16:06:22.824206 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:06:22.826522 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id as staff_store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:06:22.856039 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.860412 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d89f9f110>]}
[0m16:06:22.861595 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_stag`.`stg_staff` ..................... [[32mOK[0m in 0.06s]
[0m16:06:22.862731 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:06:22.863575 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:06:22.864486 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_stag`.`stg_store` .......................... [RUN]
[0m16:06:22.866236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:06:22.867369 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:06:22.881157 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:06:22.882519 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:06:22.887275 [debug] [Thread-1 (]: Creating new relation stg_store
[0m16:06:22.889304 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:06:22.891069 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:06:22.923462 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:06:22.928190 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d8a0c8080>]}
[0m16:06:22.929458 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_stag`.`stg_store` ..................... [[32mOK[0m in 0.06s]
[0m16:06:22.930894 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:06:22.931669 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:06:22.932510 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star`.`dim_customer` ................ [RUN]
[0m16:06:22.934060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:06:22.934730 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:06:22.941958 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:06:22.943229 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:06:23.077170 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


          )
        
        ...
[0m16:06:23.102664 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:06:23.137752 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:06:23.145646 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:23.154300 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:06:23.155524 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_customer`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


  
    ...
[0m16:06:23.286423 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.13 seconds
[0m16:06:23.423642 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d89fc1400>]}
[0m16:06:23.425068 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star`.`dim_customer` ........... [[32mOK[0m in 0.49s]
[0m16:06:23.426822 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:06:23.428115 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:06:23.429123 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star`.`dim_film` .................... [RUN]
[0m16:06:23.430190 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:06:23.431174 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:06:23.438251 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:06:23.439383 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:06:23.450411 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star`.`dim_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


          )
        
        ...
[0m16:06:23.470377 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:06:23.476739 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:06:23.483891 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:23.489488 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:06:23.491098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_film`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


  
    ...
[0m16:06:23.642474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:06:23.646884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d89f5d190>]}
[0m16:06:23.648024 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star`.`dim_film` ............... [[32mOK[0m in 0.22s]
[0m16:06:23.649112 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:06:23.650031 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:06:23.651379 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star`.`dim_staff` ................... [RUN]
[0m16:06:23.652509 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:06:23.653224 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:06:23.661622 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:06:23.662951 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:06:23.669820 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


          )
        
        ...
[0m16:06:23.690429 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:06:23.696504 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:06:23.703825 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:23.708458 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_staff"
[0m16:06:23.710437 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_staff`
        ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update")

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    staff_store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


  
    ...
[0m16:06:23.831549 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.12 seconds
[0m16:06:23.835261 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d89f9eae0>]}
[0m16:06:23.836233 [info ] [Thread-1 (]: 8 of 10 OK created sql incremental model `adw09_star`.`dim_staff` .............. [[32mOK[0m in 0.18s]
[0m16:06:23.837327 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:06:23.838106 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:06:23.838934 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star`.`dim_store` ................... [RUN]
[0m16:06:23.839967 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:06:23.840839 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:06:23.848259 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:06:23.849523 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:06:23.861963 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star`.`dim_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


          )
        
        ...
[0m16:06:23.885420 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:06:23.890808 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:06:23.899275 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:06:23.903901 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:06:23.905206 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_store`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


  
    ...
[0m16:06:24.068649 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.16 seconds
[0m16:06:24.072497 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d8a032f30>]}
[0m16:06:24.073666 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star`.`dim_store` .............. [[32mOK[0m in 0.23s]
[0m16:06:24.075178 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:06:24.077438 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:06:24.078546 [info ] [Thread-1 (]: 10 of 10 START sql incremental model `adw09_star`.`fct_rentals` ................ [RUN]
[0m16:06:24.079532 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_store, now model.sakstar.fct_rentals)
[0m16:06:24.080482 [debug] [Thread-1 (]: Began compiling node model.sakstar.fct_rentals
[0m16:06:24.092390 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.fct_rentals"
[0m16:06:24.094561 [debug] [Thread-1 (]: Began executing node model.sakstar.fct_rentals
[0m16:06:24.102455 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.fct_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

            

    
        create table `adw09_star`.`fct_rentals`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

with stg_rentals as (
    select
        rental_id,
        customer_id,
        film_id,
        staff_id,
        rental_date,
        count_rentals,
        rental_duration
    from `adw09_stag`.`stg_rentals`
    
),

dim_customer as (
    select customer_id, customer_skey
    from `adw09_star`.`dim_customer`
),

dim_film as (
    select film_id, film_skey
    from `adw09_star`.`dim_film`
),

dim_staff as (
    select staff_id, staff_skey, store_id
    from `adw09_star`.`dim_staff`
),

dim_store as (
    select store_id, store_skey
    from `adw09_star`.`dim_store`
),

dim_date as (
    select date_actual, date_key
    from `adw09_star`.`dim_date`
)

select
    lower(hex(MD5(toString(coalesce(cast(stg_rentals.rental_id as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey,
    dim_customer.customer_skey,
    dim_film.film_skey,
    dim_staff.staff_skey,
    dim_store.store_skey,
    dim_date.date_key,
    stg_rentals.rental_id,
    stg_rentals.count_rentals,
    stg_rentals.rental_duration
from stg_rentals
left join dim_customer
    on stg_rentals.customer_id = dim_customer.customer_id
left join dim_film
    on stg_rentals.film_id = dim_film.film_id
left join dim_staff
    on stg_rentals.staff_id = dim_staff.staff_id
LEFT JOIN dim_store 
    ON dim_staff.store_id = dim_store.store_id
left join dim_date
    on cast(stg_rentals.rental_date as date) = dim_date.date_actual
          )
        
        ...
[0m16:06:24.113280 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

            

    
        create table `adw09_star`.`fct_rentals`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

with stg_rentals as (
    select
        rental_id,
        customer_id,
        film_id,
        staff_id,
        rental_date,
        count_rentals,
        rental_duration
    from `adw09_stag`.`stg_rentals`
    
),

dim_customer as (
    select customer_id, customer_skey
    from `adw09_star`.`dim_customer`
),

dim_film as (
    select film_id, film_skey
    from `adw09_star`.`dim_film`
),

dim_staff as (
    select staff_id, staff_skey, store_id
    from `adw09_star`.`dim_staff`
),

dim_store as (
    select store_id, store_skey
    from `adw09_star`.`dim_store`
),

dim_date as (
    select date_actual, date_key
    from `adw09_star`.`dim_date`
)

select
    lower(hex(MD5(toString(coalesce(cast(stg_rentals.rental_id as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey,
    dim_customer.customer_skey,
    dim_film.film_skey,
    dim_staff.staff_skey,
    dim_store.store_skey,
    dim_date.date_key,
    stg_rentals.rental_id,
    stg_rentals.count_rentals,
    stg_rentals.rental_duration
from stg_rentals
left join dim_customer
    on stg_rentals.customer_id = dim_customer.customer_id
left join dim_film
    on stg_rentals.film_id = dim_film.film_id
left join dim_staff
    on stg_rentals.staff_id = dim_staff.staff_id
LEFT JOIN dim_store 
    ON dim_staff.store_id = dim_store.store_id
left join dim_date
    on cast(stg_rentals.rental_date as date) = dim_date.date_actual
          )
        
        
[0m16:06:24.123504 [debug] [Thread-1 (]: Database Error in model fct_rentals (models/marts/fact/fct_rentals/fct_rentals.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `store_id` in scope dim_staff AS (SELECT staff_id, staff_skey, store_id FROM adw09_star.dim_staff). Maybe you meant: ['staff_id']. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m16:06:24.125167 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b5b9db1-f28f-41f1-9657-3a5ddc126c76', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d89fd1220>]}
[0m16:06:24.126707 [error] [Thread-1 (]: 10 of 10 ERROR creating sql incremental model `adw09_star`.`fct_rentals` ....... [[31mERROR[0m in 0.05s]
[0m16:06:24.128362 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:06:24.133993 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:06:24.134850 [debug] [MainThread]: Connection 'model.sakstar.fct_rentals' was left open.
[0m16:06:24.135586 [debug] [MainThread]: On model.sakstar.fct_rentals: Close
[0m16:06:24.137143 [info ] [MainThread]: 
[0m16:06:24.138315 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 2.84 seconds (2.84s).
[0m16:06:24.154441 [debug] [MainThread]: Command end result
[0m16:06:24.237425 [info ] [MainThread]: 
[0m16:06:24.238444 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:06:24.239183 [info ] [MainThread]: 
[0m16:06:24.240197 [error] [MainThread]:   Database Error in model fct_rentals (models/marts/fact/fct_rentals/fct_rentals.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 47
   Code: 47. DB::Exception: Unknown expression identifier `store_id` in scope dim_staff AS (SELECT staff_id, staff_skey, store_id FROM adw09_star.dim_staff). Maybe you meant: ['staff_id']. (UNKNOWN_IDENTIFIER) (version 25.4.1.2934 (official build))
[0m16:06:24.241112 [info ] [MainThread]: 
[0m16:06:24.241869 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=1 SKIP=0 TOTAL=10
[0m16:06:24.243647 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.880472, "process_in_blocks": "0", "process_kernel_time": 1.085662, "process_mem_max_rss": "211672", "process_out_blocks": "4984", "process_user_time": 10.388493}
[0m16:06:24.244376 [debug] [MainThread]: Command `dbt run` failed at 16:06:24.244213 after 7.88 seconds
[0m16:06:24.245066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0e32e5a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0c0463c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e0c0459a0>]}
[0m16:06:24.245624 [debug] [MainThread]: Flushing usage events
[0m16:07:17.027728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79436e7fb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7943767d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7943743380>]}


============================== 16:07:17.033167 | 35d7a9c1-545a-4c21-a267-19442aa8d4b4 ==============================
[0m16:07:17.033167 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:07:17.034100 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'profiles_dir': '/home/jovyan/dbt/workspace', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:07:17.374607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7943211b20>]}
[0m16:07:17.482842 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79433037d0>]}
[0m16:07:17.484325 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:07:17.678454 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:07:17.934709 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m16:07:17.935934 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/marts/dim/dim_staff/dim_staff.sql
[0m16:07:17.937170 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/marts/staging/stg_staff.sql
[0m16:07:18.437173 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:07:18.438067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79433d92b0>]}
[0m16:07:18.776068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7942c87d70>]}
[0m16:07:18.995281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7944aaeb10>]}
[0m16:07:18.996461 [info ] [MainThread]: Found 10 models, 1 snapshot, 23 data tests, 13 sources, 605 macros
[0m16:07:18.997278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79430bb440>]}
[0m16:07:19.001336 [info ] [MainThread]: 
[0m16:07:19.002679 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:07:19.014333 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:07:19.034198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:07:20.020838 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:07:20.026722 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:20.054254 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:07:20.061150 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:20.066608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw09_star)
[0m16:07:20.078344 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:07:20.104506 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:20.108267 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__adw09_stag)
[0m16:07:20.116033 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_stag'
      

  ...
[0m16:07:20.140272 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:20.144249 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_stag, now list__star)
[0m16:07:20.150394 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'star'
      

  ...
[0m16:07:20.179214 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:20.182617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78cc0f3920>]}
[0m16:07:20.183788 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:07:20.184555 [info ] [MainThread]: 
[0m16:07:20.190625 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:07:20.192588 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_stag`.`stg_customer` ....................... [RUN]
[0m16:07:20.193860 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__star, now model.sakstar.stg_customer)
[0m16:07:20.194697 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:07:20.214021 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:07:20.215299 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:07:20.241514 [debug] [Thread-1 (]: Relation stg_customer already exists, replacing it
[0m16:07:20.260639 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:07:20.262151 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:20.292967 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:20.335018 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7942c253a0>]}
[0m16:07:20.336449 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_stag`.`stg_customer` .................. [[32mOK[0m in 0.14s]
[0m16:07:20.337739 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:07:20.338601 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:07:20.339621 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_stag`.`stg_film` ........................... [RUN]
[0m16:07:20.341881 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:07:20.342664 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:07:20.352527 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:07:20.353661 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:07:20.357761 [debug] [Thread-1 (]: Relation stg_film already exists, replacing it
[0m16:07:20.359607 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:07:20.361021 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:20.393762 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:20.398235 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c1cf84a0>]}
[0m16:07:20.399347 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m16:07:20.400633 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:07:20.401458 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:07:20.402261 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_stag`.`stg_rentals` ........................ [RUN]
[0m16:07:20.403126 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:07:20.403884 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:07:20.414791 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:07:20.416644 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:07:20.423174 [debug] [Thread-1 (]: Relation stg_rentals already exists, replacing it
[0m16:07:20.425268 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:07:20.426968 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:20.450795 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:20.454466 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c1c0e960>]}
[0m16:07:20.455473 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_stag`.`stg_rentals` ................... [[32mOK[0m in 0.05s]
[0m16:07:20.457111 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:07:20.458305 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:07:20.459468 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_stag`.`stg_staff` .......................... [RUN]
[0m16:07:20.460991 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:07:20.461683 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:07:20.470684 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:07:20.471764 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:07:20.477331 [debug] [Thread-1 (]: Relation stg_staff already exists, replacing it
[0m16:07:20.479147 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:07:20.480544 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:20.510262 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:20.514446 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c1c0ec00>]}
[0m16:07:20.515541 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_stag`.`stg_staff` ..................... [[32mOK[0m in 0.05s]
[0m16:07:20.516661 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:07:20.517540 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:07:20.518494 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_stag`.`stg_store` .......................... [RUN]
[0m16:07:20.520082 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:07:20.520729 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:07:20.530680 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:07:20.532045 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:07:20.535674 [debug] [Thread-1 (]: Relation stg_store already exists, replacing it
[0m16:07:20.537162 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:07:20.538725 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:20.570942 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:20.575313 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c1c0eb10>]}
[0m16:07:20.576476 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_stag`.`stg_store` ..................... [[32mOK[0m in 0.06s]
[0m16:07:20.577652 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:07:20.578533 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:07:20.579490 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star`.`dim_customer` ................ [RUN]
[0m16:07:20.581203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:07:20.581888 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:07:20.592407 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:07:20.594000 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:07:20.817016 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:07:20.821292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:20.880344 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star`.`dim_customer__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

          )
        
        ...
[0m16:07:20.900325 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:20.935042 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:20.942746 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:20.950422 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_customer__dbt_new_data`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

  
      ...
[0m16:07:21.089157 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.14 seconds
[0m16:07:21.092398 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:07:21.093927 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

          create table `adw09_star`.`dim_customer__dbt_tmp` 
   as `adw09_star`.`dim_customer__dbt_new_data`
      ...
[0m16:07:21.111832 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:21.116692 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:21.123999 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.127869 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer`
          where (customer_id) not in (
            select customer_id
            from `adw09_star`.`dim_customer__dbt_new_data`
          )
       
    ...
[0m16:07:21.142993 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.145212 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

     insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer__dbt_new_data`
      
    ...
[0m16:07:21.151449 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.157683 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:07:21.162612 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.175177 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:07:21.179492 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.181652 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    rename table `adw09_star`.`dim_customer__dbt_tmp` to `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:07:21.185793 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.195351 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */
EXCHANGE TABLES `adw09_star`.`dim_customer__dbt_backup` AND `adw09_star`.`dim_customer` 
  
  ...
[0m16:07:21.200105 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.208040 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  ...
[0m16:07:21.212617 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.215140 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c2108ad0>]}
[0m16:07:21.216208 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star`.`dim_customer` ........... [[32mOK[0m in 0.63s]
[0m16:07:21.217305 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:07:21.218083 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:07:21.218973 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star`.`dim_film` .................... [RUN]
[0m16:07:21.219957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:07:21.220697 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:07:21.228688 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:07:21.230022 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:07:21.242128 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:07:21.246228 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.249426 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star`.`dim_film__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

          )
        
        ...
[0m16:07:21.271483 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:21.278073 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:21.285355 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.288394 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_film__dbt_new_data`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

  
      ...
[0m16:07:21.446380 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.16 seconds
[0m16:07:21.448612 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:07:21.449640 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

          create table `adw09_star`.`dim_film__dbt_tmp` 
   as `adw09_star`.`dim_film__dbt_new_data`
      ...
[0m16:07:21.467685 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:21.472625 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:21.480591 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.483486 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film`
          where (film_id) not in (
            select film_id
            from `adw09_star`.`dim_film__dbt_new_data`
          )
       
    ...
[0m16:07:21.491927 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.493951 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

     insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film__dbt_new_data`
      
    ...
[0m16:07:21.500113 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.505354 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:07:21.509964 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.515964 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:07:21.520173 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.522196 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    rename table `adw09_star`.`dim_film__dbt_tmp` to `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:07:21.526578 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.528913 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */
EXCHANGE TABLES `adw09_star`.`dim_film__dbt_backup` AND `adw09_star`.`dim_film` 
  
  ...
[0m16:07:21.533001 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.539558 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  ...
[0m16:07:21.543272 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.546136 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c1bf32c0>]}
[0m16:07:21.547171 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star`.`dim_film` ............... [[32mOK[0m in 0.33s]
[0m16:07:21.548435 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:07:21.549227 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:07:21.550217 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star`.`dim_staff` ................... [RUN]
[0m16:07:21.551462 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:07:21.552127 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:07:21.559013 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:07:21.560302 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:07:21.571970 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_new_data` 
  ...
[0m16:07:21.576941 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.581198 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star`.`dim_staff__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


WHERE staff_last_update > (SELECT max(staff_last_update) FROM `adw09_star`.`dim_staff`)

          )
        
        ...
[0m16:07:21.600924 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:21.607157 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:21.614030 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.616742 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_staff__dbt_new_data`
        ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update")

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


WHERE staff_last_update > (SELECT max(staff_last_update) FROM `adw09_star`.`dim_staff`)

  
      ...
[0m16:07:21.733808 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.12 seconds
[0m16:07:21.735819 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_staff"
[0m16:07:21.736853 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

          create table `adw09_star`.`dim_staff__dbt_tmp` 
   as `adw09_star`.`dim_staff__dbt_new_data`
      ...
[0m16:07:21.755675 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:21.761432 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:21.768257 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.771876 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        insert into `adw09_star`.`dim_staff__dbt_tmp` ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update")
        select "staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update"
        from `adw09_star`.`dim_staff`
          where (staff_id) not in (
            select staff_id
            from `adw09_star`.`dim_staff__dbt_new_data`
          )
       
    ...
[0m16:07:21.777402 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        insert into `adw09_star`.`dim_staff__dbt_tmp` ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update")
        select "staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update"
        from `adw09_star`.`dim_staff`
          where (staff_id) not in (
            select staff_id
            from `adw09_star`.`dim_staff__dbt_new_data`
          )
       
    
[0m16:07:21.784126 [debug] [Thread-1 (]: Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 16
   Code: 16. DB::Exception: No such column staff_store_id in table adw09_star.dim_staff__dbt_tmp (72086c72-b5b0-4d1c-b230-e972fad7a00b). (NO_SUCH_COLUMN_IN_TABLE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/dim/dim_staff/dim_staff.sql
[0m16:07:21.784928 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c1cbf320>]}
[0m16:07:21.785936 [error] [Thread-1 (]: 8 of 10 ERROR creating sql incremental model `adw09_star`.`dim_staff` .......... [[31mERROR[0m in 0.23s]
[0m16:07:21.787067 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:07:21.787798 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:07:21.788716 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star`.`dim_store` ................... [RUN]
[0m16:07:21.790209 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:07:21.791171 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:07:21.800136 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:07:21.801829 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:07:21.814643 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:07:21.818627 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:21.821997 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star`.`dim_store__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

          )
        
        ...
[0m16:07:21.843780 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:21.849600 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:21.856758 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:21.860513 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_store__dbt_new_data`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

  
      ...
[0m16:07:22.011839 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:07:22.013907 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:07:22.015373 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

          create table `adw09_star`.`dim_store__dbt_tmp` 
   as `adw09_star`.`dim_store__dbt_new_data`
      ...
[0m16:07:22.034425 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:22.039396 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:22.046471 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:22.049210 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store`
          where (store_id) not in (
            select store_id
            from `adw09_star`.`dim_store__dbt_new_data`
          )
       
    ...
[0m16:07:22.061764 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:22.063822 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

     insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store__dbt_new_data`
      
    ...
[0m16:07:22.070001 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:22.075810 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:07:22.080116 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:22.088346 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:07:22.092428 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:22.094371 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    rename table `adw09_star`.`dim_store__dbt_tmp` to `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:07:22.098566 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:22.100554 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */
EXCHANGE TABLES `adw09_star`.`dim_store__dbt_backup` AND `adw09_star`.`dim_store` 
  
  ...
[0m16:07:22.104365 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:22.111655 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  ...
[0m16:07:22.115448 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:22.118463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d7a9c1-545a-4c21-a267-19442aa8d4b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c02d3350>]}
[0m16:07:22.119493 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star`.`dim_store` .............. [[32mOK[0m in 0.33s]
[0m16:07:22.120812 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:07:22.122637 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:07:22.123810 [info ] [Thread-1 (]: 10 of 10 SKIP relation adw09_star.fct_rentals .................................. [[33mSKIP[0m]
[0m16:07:22.125217 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:07:22.128587 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:07:22.129153 [debug] [MainThread]: Connection 'model.sakstar.dim_store' was left open.
[0m16:07:22.129622 [debug] [MainThread]: On model.sakstar.dim_store: Close
[0m16:07:22.130581 [info ] [MainThread]: 
[0m16:07:22.131273 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 3.13 seconds (3.13s).
[0m16:07:22.134262 [debug] [MainThread]: Command end result
[0m16:07:22.205392 [info ] [MainThread]: 
[0m16:07:22.206448 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:07:22.207223 [info ] [MainThread]: 
[0m16:07:22.208482 [error] [MainThread]:   Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 16
   Code: 16. DB::Exception: No such column staff_store_id in table adw09_star.dim_staff__dbt_tmp (72086c72-b5b0-4d1c-b230-e972fad7a00b). (NO_SUCH_COLUMN_IN_TABLE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/dim/dim_staff/dim_staff.sql
[0m16:07:22.209460 [info ] [MainThread]: 
[0m16:07:22.210202 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=1 TOTAL=10
[0m16:07:22.212020 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.269511, "process_in_blocks": "0", "process_kernel_time": 1.000673, "process_mem_max_rss": "210544", "process_out_blocks": "5016", "process_user_time": 7.648715}
[0m16:07:22.212854 [debug] [MainThread]: Command `dbt run` failed at 16:07:22.212624 after 5.27 seconds
[0m16:07:22.213544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f78c27ae030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7943716a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f794489b920>]}
[0m16:07:22.214214 [debug] [MainThread]: Flushing usage events
[0m16:07:53.372582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef581acc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef5d606e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef657f7d0>]}


============================== 16:07:53.378584 | 9972aac5-3696-4536-9ec6-8bc634041d42 ==============================
[0m16:07:53.378584 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:07:53.379539 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:07:53.721210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef54eec30>]}
[0m16:07:53.830471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef61563f0>]}
[0m16:07:53.831891 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:07:54.010650 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:07:54.303509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:07:54.305161 [debug] [MainThread]: Partial parsing: updated file: sakstar://snapshots/dstaff_snapshot.sql
[0m16:07:54.723850 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m16:07:54.724875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef4d269c0>]}
[0m16:07:55.060319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef4c24cb0>]}
[0m16:07:55.285748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef4b6ac90>]}
[0m16:07:55.286777 [info ] [MainThread]: Found 10 models, 23 data tests, 1 snapshot, 13 sources, 605 macros
[0m16:07:55.287640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef4d33b90>]}
[0m16:07:55.293566 [info ] [MainThread]: 
[0m16:07:55.294682 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:07:55.306323 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:07:55.329198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:07:56.302021 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:07:56.307116 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:56.335645 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:07:56.341683 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:56.346951 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__star)
[0m16:07:56.360466 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'star'
      

  ...
[0m16:07:56.392560 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:56.395153 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__star, now list__adw09_star)
[0m16:07:56.399108 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:07:56.425737 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:56.428715 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__adw09_stag)
[0m16:07:56.432625 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_stag'
      

  ...
[0m16:07:56.459624 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:56.464461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef4f8b4a0>]}
[0m16:07:56.465396 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:07:56.466120 [info ] [MainThread]: 
[0m16:07:56.471586 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:07:56.472686 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_stag`.`stg_customer` ....................... [RUN]
[0m16:07:56.473772 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_stag, now model.sakstar.stg_customer)
[0m16:07:56.474373 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:07:56.514573 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:07:56.515838 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:07:56.545654 [debug] [Thread-1 (]: Relation stg_customer already exists, replacing it
[0m16:07:56.569354 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:07:56.571047 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:56.601182 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:56.648818 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef6ed4260>]}
[0m16:07:56.650258 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_stag`.`stg_customer` .................. [[32mOK[0m in 0.17s]
[0m16:07:56.651504 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:07:56.652611 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:07:56.653547 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_stag`.`stg_film` ........................... [RUN]
[0m16:07:56.654468 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:07:56.655705 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:07:56.668188 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:07:56.669519 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:07:56.674270 [debug] [Thread-1 (]: Relation stg_film already exists, replacing it
[0m16:07:56.676046 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:07:56.677427 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:56.710550 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:56.714952 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe73b9e870>]}
[0m16:07:56.715989 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m16:07:56.717037 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:07:56.717956 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:07:56.718773 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_stag`.`stg_rentals` ........................ [RUN]
[0m16:07:56.720904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:07:56.721549 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:07:56.732365 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:07:56.733611 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:07:56.737449 [debug] [Thread-1 (]: Relation stg_rentals already exists, replacing it
[0m16:07:56.739523 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:07:56.741493 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:56.764472 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:56.768511 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe73c2ae70>]}
[0m16:07:56.769600 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_stag`.`stg_rentals` ................... [[32mOK[0m in 0.05s]
[0m16:07:56.771000 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:07:56.771871 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:07:56.773454 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_stag`.`stg_staff` .......................... [RUN]
[0m16:07:56.774741 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:07:56.775407 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:07:56.785539 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:07:56.787346 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:07:56.795299 [debug] [Thread-1 (]: Relation stg_staff already exists, replacing it
[0m16:07:56.797627 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:07:56.798909 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:56.828375 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:56.832504 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe73c39fd0>]}
[0m16:07:56.833690 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_stag`.`stg_staff` ..................... [[32mOK[0m in 0.06s]
[0m16:07:56.834962 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:07:56.836050 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:07:56.836908 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_stag`.`stg_store` .......................... [RUN]
[0m16:07:56.838098 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:07:56.839097 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:07:56.849614 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:07:56.850961 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:07:56.854748 [debug] [Thread-1 (]: Relation stg_store already exists, replacing it
[0m16:07:56.856782 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:07:56.858105 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:07:56.888982 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:56.893424 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe73c38170>]}
[0m16:07:56.894602 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_stag`.`stg_store` ..................... [[32mOK[0m in 0.06s]
[0m16:07:56.895854 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:07:56.896727 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:07:56.898147 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star`.`dim_customer` ................ [RUN]
[0m16:07:56.899080 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:07:56.899986 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:07:56.917616 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:07:56.918933 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:07:57.028207 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:07:57.032354 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.089485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star`.`dim_customer__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

          )
        
        ...
[0m16:07:57.116255 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:07:57.283995 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:57.292555 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.299106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_customer__dbt_new_data`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

  
      ...
[0m16:07:57.432609 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.13 seconds
[0m16:07:57.434756 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:07:57.436063 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

          create table `adw09_star`.`dim_customer__dbt_tmp` 
   as `adw09_star`.`dim_customer__dbt_new_data`
      ...
[0m16:07:57.454371 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:57.459705 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:57.467805 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.471252 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer`
          where (customer_id) not in (
            select customer_id
            from `adw09_star`.`dim_customer__dbt_new_data`
          )
       
    ...
[0m16:07:57.486353 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.488741 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

     insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer__dbt_new_data`
      
    ...
[0m16:07:57.496092 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.502383 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:07:57.506411 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.520591 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:07:57.525931 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.528182 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    rename table `adw09_star`.`dim_customer__dbt_tmp` to `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:07:57.533789 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.542440 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */
EXCHANGE TABLES `adw09_star`.`dim_customer__dbt_backup` AND `adw09_star`.`dim_customer` 
  
  ...
[0m16:07:57.547920 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.555438 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  ...
[0m16:07:57.560933 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.563668 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe73c24980>]}
[0m16:07:57.564792 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star`.`dim_customer` ........... [[32mOK[0m in 0.66s]
[0m16:07:57.565914 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:07:57.566856 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:07:57.567822 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star`.`dim_film` .................... [RUN]
[0m16:07:57.568951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:07:57.570102 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:07:57.578002 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:07:57.579479 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:07:57.590576 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:07:57.595819 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.599314 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star`.`dim_film__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

          )
        
        ...
[0m16:07:57.619982 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:57.629105 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:57.636533 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.640629 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_film__dbt_new_data`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

  
      ...
[0m16:07:57.867286 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.23 seconds
[0m16:07:57.870815 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:07:57.872327 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

          create table `adw09_star`.`dim_film__dbt_tmp` 
   as `adw09_star`.`dim_film__dbt_new_data`
      ...
[0m16:07:57.891141 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:57.896097 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:57.903564 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.907440 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film`
          where (film_id) not in (
            select film_id
            from `adw09_star`.`dim_film__dbt_new_data`
          )
       
    ...
[0m16:07:57.916027 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.918020 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

     insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film__dbt_new_data`
      
    ...
[0m16:07:57.924168 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:57.929664 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:07:57.933815 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.939284 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:07:57.943783 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.945732 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    rename table `adw09_star`.`dim_film__dbt_tmp` to `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:07:57.949618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.951685 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */
EXCHANGE TABLES `adw09_star`.`dim_film__dbt_backup` AND `adw09_star`.`dim_film` 
  
  ...
[0m16:07:57.955821 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.962898 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  ...
[0m16:07:57.967914 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:57.970756 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe73be0e90>]}
[0m16:07:57.971853 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star`.`dim_film` ............... [[32mOK[0m in 0.40s]
[0m16:07:57.973296 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:07:57.974112 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:07:57.975264 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star`.`dim_staff` ................... [RUN]
[0m16:07:57.976498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:07:57.977246 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:07:57.983854 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:07:57.985134 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:07:57.995743 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_tmp` 
  ...
[0m16:07:58.000871 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.007465 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_new_data` 
  ...
[0m16:07:58.012163 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.015674 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star`.`dim_staff__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


WHERE staff_last_update > (SELECT max(staff_last_update) FROM `adw09_star`.`dim_staff`)

          )
        
        ...
[0m16:07:58.035212 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:58.044950 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:58.052078 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:58.055116 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_staff__dbt_new_data`
        ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update")

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


WHERE staff_last_update > (SELECT max(staff_last_update) FROM `adw09_star`.`dim_staff`)

  
      ...
[0m16:07:58.179164 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.12 seconds
[0m16:07:58.181565 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_staff"
[0m16:07:58.182762 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

          create table `adw09_star`.`dim_staff__dbt_tmp` 
   as `adw09_star`.`dim_staff__dbt_new_data`
      ...
[0m16:07:58.201121 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:58.206374 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:58.213950 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:58.216800 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        insert into `adw09_star`.`dim_staff__dbt_tmp` ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update")
        select "staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update"
        from `adw09_star`.`dim_staff`
          where (staff_id) not in (
            select staff_id
            from `adw09_star`.`dim_staff__dbt_new_data`
          )
       
    ...
[0m16:07:58.222036 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        insert into `adw09_star`.`dim_staff__dbt_tmp` ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update")
        select "staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "staff_store_id", "staff_active", "staff_last_update"
        from `adw09_star`.`dim_staff`
          where (staff_id) not in (
            select staff_id
            from `adw09_star`.`dim_staff__dbt_new_data`
          )
       
    
[0m16:07:58.230475 [debug] [Thread-1 (]: Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 16
   Code: 16. DB::Exception: No such column staff_store_id in table adw09_star.dim_staff__dbt_tmp (b856cd8a-830b-4e13-89da-282658611092). (NO_SUCH_COLUMN_IN_TABLE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/dim/dim_staff/dim_staff.sql
[0m16:07:58.231511 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe7226ffe0>]}
[0m16:07:58.232561 [error] [Thread-1 (]: 8 of 10 ERROR creating sql incremental model `adw09_star`.`dim_staff` .......... [[31mERROR[0m in 0.26s]
[0m16:07:58.233783 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:07:58.234565 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:07:58.235382 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star`.`dim_store` ................... [RUN]
[0m16:07:58.237739 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:07:58.238610 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:07:58.246259 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:07:58.247501 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:07:58.257332 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:07:58.261696 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.265290 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star`.`dim_store__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

          )
        
        ...
[0m16:07:58.287185 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:58.294861 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:58.303317 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:58.307352 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_store__dbt_new_data`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

  
      ...
[0m16:07:58.469132 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.16 seconds
[0m16:07:58.472321 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:07:58.474315 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

          create table `adw09_star`.`dim_store__dbt_tmp` 
   as `adw09_star`.`dim_store__dbt_new_data`
      ...
[0m16:07:58.493222 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:07:58.499289 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:07:58.509321 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:58.512733 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store`
          where (store_id) not in (
            select store_id
            from `adw09_star`.`dim_store__dbt_new_data`
          )
       
    ...
[0m16:07:58.527173 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:58.529435 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

     insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store__dbt_new_data`
      
    ...
[0m16:07:58.536932 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:07:58.544582 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:07:58.548990 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.556219 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:07:58.560442 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.562656 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    rename table `adw09_star`.`dim_store__dbt_tmp` to `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:07:58.567274 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.569833 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */
EXCHANGE TABLES `adw09_star`.`dim_store__dbt_backup` AND `adw09_star`.`dim_store` 
  
  ...
[0m16:07:58.575217 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.586689 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  ...
[0m16:07:58.592563 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:07:58.596681 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9972aac5-3696-4536-9ec6-8bc634041d42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe7233dca0>]}
[0m16:07:58.597986 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star`.`dim_store` .............. [[32mOK[0m in 0.36s]
[0m16:07:58.599308 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:07:58.602156 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:07:58.603056 [info ] [Thread-1 (]: 10 of 10 SKIP relation adw09_star.fct_rentals .................................. [[33mSKIP[0m]
[0m16:07:58.604205 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:07:58.609458 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:07:58.610559 [debug] [MainThread]: Connection 'model.sakstar.dim_store' was left open.
[0m16:07:58.611113 [debug] [MainThread]: On model.sakstar.dim_store: Close
[0m16:07:58.612309 [info ] [MainThread]: 
[0m16:07:58.613686 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 3.32 seconds (3.32s).
[0m16:07:58.619015 [debug] [MainThread]: Command end result
[0m16:07:58.710103 [info ] [MainThread]: 
[0m16:07:58.711182 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:07:58.712165 [info ] [MainThread]: 
[0m16:07:58.713524 [error] [MainThread]:   Database Error in model dim_staff (models/marts/dim/dim_staff/dim_staff.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 16
   Code: 16. DB::Exception: No such column staff_store_id in table adw09_star.dim_staff__dbt_tmp (b856cd8a-830b-4e13-89da-282658611092). (NO_SUCH_COLUMN_IN_TABLE) (version 25.4.1.2934 (official build))
  compiled code at target/run/sakstar/models/marts/dim/dim_staff/dim_staff.sql
[0m16:07:58.714380 [info ] [MainThread]: 
[0m16:07:58.715228 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=1 TOTAL=10
[0m16:07:58.718251 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.4326224, "process_in_blocks": "0", "process_kernel_time": 1.041621, "process_mem_max_rss": "210284", "process_out_blocks": "5016", "process_user_time": 7.611852}
[0m16:07:58.719191 [debug] [MainThread]: Command `dbt run` failed at 16:07:58.718947 after 5.43 seconds
[0m16:07:58.720174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef5a0cb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbef5a0cd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe7b47ab40>]}
[0m16:07:58.720925 [debug] [MainThread]: Flushing usage events
[0m16:10:58.597298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1bc53560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1b3c3c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1ab18770>]}


============================== 16:10:58.604743 | 4d932c03-7531-4c82-b760-847d627a9d13 ==============================
[0m16:10:58.604743 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:10:58.606450 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/jovyan/dbt/workspace', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m16:10:58.953372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1a8686e0>]}
[0m16:10:59.056771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1ada8ce0>]}
[0m16:10:59.058498 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:10:59.220632 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:10:59.465475 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:10:59.466191 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:10:59.569937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1a86a7b0>]}
[0m16:10:59.816404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1a620dd0>]}
[0m16:10:59.817444 [info ] [MainThread]: Found 10 models, 23 data tests, 1 snapshot, 13 sources, 605 macros
[0m16:10:59.818685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1a44ec00>]}
[0m16:10:59.824119 [info ] [MainThread]: 
[0m16:10:59.825396 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:10:59.837987 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:10:59.864254 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:11:00.804103 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:11:00.809219 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:00.845838 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:11:00.851734 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:00.855482 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__adw09_stag)
[0m16:11:00.856720 [debug] [ThreadPool]: Creating schema "schema: "adw09_stag"
"
[0m16:11:00.870692 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw09_stag"} */
create database if not exists `adw09_stag`
        
  
        
  ...
[0m16:11:00.879753 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:00.884682 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw09_stag, now list__adw09_star)
[0m16:11:00.896638 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:11:00.930254 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:00.933354 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_star, now list__star)
[0m16:11:00.938993 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'star'
      

  ...
[0m16:11:00.965817 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:00.968375 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__star, now list__adw09_stag)
[0m16:11:00.973221 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_stag'
      

  ...
[0m16:11:00.999583 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:01.002703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9986adb0>]}
[0m16:11:01.004169 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:11:01.004924 [info ] [MainThread]: 
[0m16:11:01.011484 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:11:01.012413 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_stag`.`stg_customer` ....................... [RUN]
[0m16:11:01.013398 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_stag, now model.sakstar.stg_customer)
[0m16:11:01.014239 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:11:01.054498 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:11:01.055938 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:11:01.081146 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m16:11:01.096208 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:11:01.097540 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:01.127842 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:01.162008 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9900fa10>]}
[0m16:11:01.163146 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_stag`.`stg_customer` .................. [[32mOK[0m in 0.15s]
[0m16:11:01.164508 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:11:01.165358 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:11:01.166177 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_stag`.`stg_film` ........................... [RUN]
[0m16:11:01.167556 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:11:01.168267 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:11:01.178600 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:11:01.180170 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:11:01.184548 [debug] [Thread-1 (]: Creating new relation stg_film
[0m16:11:01.186583 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:11:01.188032 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:01.220104 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:01.223830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d99146f00>]}
[0m16:11:01.224952 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m16:11:01.226048 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:11:01.226814 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:11:01.227646 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_stag`.`stg_rentals` ........................ [RUN]
[0m16:11:01.229279 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:11:01.230342 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:11:01.240515 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:11:01.241627 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:11:01.245533 [debug] [Thread-1 (]: Creating new relation stg_rentals
[0m16:11:01.247301 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:11:01.248434 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:01.270836 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:01.274268 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9909ffe0>]}
[0m16:11:01.275296 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_stag`.`stg_rentals` ................... [[32mOK[0m in 0.05s]
[0m16:11:01.276303 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:11:01.277081 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:11:01.277982 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_stag`.`stg_staff` .......................... [RUN]
[0m16:11:01.279470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:11:01.280361 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:11:01.293077 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:11:01.294309 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:11:01.297839 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m16:11:01.299403 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:11:01.300846 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:01.328894 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:01.332835 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d99074230>]}
[0m16:11:01.333853 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_stag`.`stg_staff` ..................... [[32mOK[0m in 0.05s]
[0m16:11:01.334879 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:11:01.335853 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:11:01.337121 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_stag`.`stg_store` .......................... [RUN]
[0m16:11:01.338629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:11:01.339280 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:11:01.348822 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:11:01.349969 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:11:01.354281 [debug] [Thread-1 (]: Creating new relation stg_store
[0m16:11:01.355902 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:11:01.357032 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:01.389266 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:01.393255 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d990b2780>]}
[0m16:11:01.394420 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_stag`.`stg_store` ..................... [[32mOK[0m in 0.05s]
[0m16:11:01.395644 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:11:01.396405 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:11:01.397276 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star`.`dim_customer` ................ [RUN]
[0m16:11:01.398903 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:11:01.399496 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:11:01.420729 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:11:01.422143 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:11:01.522407 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:11:01.527139 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.584008 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star`.`dim_customer__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

          )
        
        ...
[0m16:11:01.610959 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:01.659511 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:01.667253 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:01.674496 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_customer__dbt_new_data`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

  
      ...
[0m16:11:01.813320 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.14 seconds
[0m16:11:01.815361 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:11:01.816492 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

          create table `adw09_star`.`dim_customer__dbt_tmp` 
   as `adw09_star`.`dim_customer__dbt_new_data`
      ...
[0m16:11:01.836714 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:01.844248 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:01.853396 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:01.858123 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer`
          where (customer_id) not in (
            select customer_id
            from `adw09_star`.`dim_customer__dbt_new_data`
          )
       
    ...
[0m16:11:01.873204 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:01.875305 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

     insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer__dbt_new_data`
      
    ...
[0m16:11:01.881736 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:01.888550 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:11:01.894101 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.907856 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:11:01.912072 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.914049 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    rename table `adw09_star`.`dim_customer__dbt_tmp` to `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:11:01.918276 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.927292 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */
EXCHANGE TABLES `adw09_star`.`dim_customer__dbt_backup` AND `adw09_star`.`dim_customer` 
  
  ...
[0m16:11:01.931931 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.938298 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  ...
[0m16:11:01.942351 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.945286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1a589910>]}
[0m16:11:01.946473 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star`.`dim_customer` ........... [[32mOK[0m in 0.55s]
[0m16:11:01.947667 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:11:01.948627 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:11:01.949468 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star`.`dim_film` .................... [RUN]
[0m16:11:01.951089 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:11:01.951757 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:11:01.961607 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:11:01.962936 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:11:01.974607 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:11:01.978520 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:01.982402 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star`.`dim_film__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

          )
        
        ...
[0m16:11:02.009920 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:02.025311 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:02.034676 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.038863 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_film__dbt_new_data`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

  
      ...
[0m16:11:02.211950 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.17 seconds
[0m16:11:02.214060 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:11:02.215337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

          create table `adw09_star`.`dim_film__dbt_tmp` 
   as `adw09_star`.`dim_film__dbt_new_data`
      ...
[0m16:11:02.234191 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:02.242013 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:02.250161 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.253505 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film`
          where (film_id) not in (
            select film_id
            from `adw09_star`.`dim_film__dbt_new_data`
          )
       
    ...
[0m16:11:02.263618 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.265916 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

     insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film__dbt_new_data`
      
    ...
[0m16:11:02.272722 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.278628 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:11:02.282757 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.289215 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:11:02.293784 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.295785 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    rename table `adw09_star`.`dim_film__dbt_tmp` to `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:11:02.300086 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.302094 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */
EXCHANGE TABLES `adw09_star`.`dim_film__dbt_backup` AND `adw09_star`.`dim_film` 
  
  ...
[0m16:11:02.306623 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.313634 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  ...
[0m16:11:02.318026 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.321021 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9905ee10>]}
[0m16:11:02.322159 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star`.`dim_film` ............... [[32mOK[0m in 0.37s]
[0m16:11:02.323499 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:11:02.324501 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:11:02.325470 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star`.`dim_staff` ................... [RUN]
[0m16:11:02.326987 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:11:02.327690 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:11:02.334300 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:11:02.335248 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:11:02.342525 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star`.`dim_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


          )
        
        ...
[0m16:11:02.361852 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:02.367617 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:02.375031 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.380036 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_staff"
[0m16:11:02.381365 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_staff`
        ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update")

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


  
    ...
[0m16:11:02.501383 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.12 seconds
[0m16:11:02.511637 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9875a960>]}
[0m16:11:02.512752 [info ] [Thread-1 (]: 8 of 10 OK created sql incremental model `adw09_star`.`dim_staff` .............. [[32mOK[0m in 0.18s]
[0m16:11:02.513871 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:11:02.514832 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:11:02.516301 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star`.`dim_store` ................... [RUN]
[0m16:11:02.517265 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:11:02.517980 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:11:02.529106 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:11:02.530774 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:11:02.540611 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:11:02.544729 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.548143 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star`.`dim_store__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

          )
        
        ...
[0m16:11:02.568606 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:02.575599 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:02.582820 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.585469 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_store__dbt_new_data`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

  
      ...
[0m16:11:02.736576 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:11:02.738683 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:11:02.740025 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

          create table `adw09_star`.`dim_store__dbt_tmp` 
   as `adw09_star`.`dim_store__dbt_new_data`
      ...
[0m16:11:02.757163 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:02.762848 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:02.771115 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.773928 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store`
          where (store_id) not in (
            select store_id
            from `adw09_star`.`dim_store__dbt_new_data`
          )
       
    ...
[0m16:11:02.785337 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.787831 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

     insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store__dbt_new_data`
      
    ...
[0m16:11:02.793870 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.799859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:11:02.804578 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.811337 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:11:02.815279 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.817412 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    rename table `adw09_star`.`dim_store__dbt_tmp` to `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:11:02.822292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.824595 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */
EXCHANGE TABLES `adw09_star`.`dim_store__dbt_backup` AND `adw09_star`.`dim_store` 
  
  ...
[0m16:11:02.829688 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.835948 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  ...
[0m16:11:02.840413 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:02.843264 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9875a4b0>]}
[0m16:11:02.844395 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star`.`dim_store` .............. [[32mOK[0m in 0.33s]
[0m16:11:02.845535 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:11:02.847250 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:11:02.848488 [info ] [Thread-1 (]: 10 of 10 START sql incremental model `adw09_star`.`fct_rentals` ................ [RUN]
[0m16:11:02.849471 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_store, now model.sakstar.fct_rentals)
[0m16:11:02.850616 [debug] [Thread-1 (]: Began compiling node model.sakstar.fct_rentals
[0m16:11:02.862333 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.fct_rentals"
[0m16:11:02.863414 [debug] [Thread-1 (]: Began executing node model.sakstar.fct_rentals
[0m16:11:02.873572 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.fct_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

            

    
        create table `adw09_star`.`fct_rentals`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

with stg_rentals as (
    select
        rental_id,
        customer_id,
        film_id,
        staff_id,
        rental_date,
        count_rentals,
        rental_duration
    from `adw09_stag`.`stg_rentals`
    
),

dim_customer as (
    select customer_id, customer_skey
    from `adw09_star`.`dim_customer`
),

dim_film as (
    select film_id, film_skey
    from `adw09_star`.`dim_film`
),

dim_staff as (
    select staff_id, staff_skey, store_id
    from `adw09_star`.`dim_staff`
),

dim_store as (
    select store_id, store_skey
    from `adw09_star`.`dim_store`
),

dim_date as (
    select date_actual, date_key
    from `adw09_star`.`dim_date`
)

select
    lower(hex(MD5(toString(coalesce(cast(stg_rentals.rental_id as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey,
    dim_customer.customer_skey,
    dim_film.film_skey,
    dim_staff.staff_skey,
    dim_store.store_skey,
    dim_date.date_key,
    stg_rentals.rental_id,
    stg_rentals.count_rentals,
    stg_rentals.rental_duration
from stg_rentals
left join dim_customer
    on stg_rentals.customer_id = dim_customer.customer_id
left join dim_film
    on stg_rentals.film_id = dim_film.film_id
left join dim_staff
    on stg_rentals.staff_id = dim_staff.staff_id
LEFT JOIN dim_store 
    ON dim_staff.store_id = dim_store.store_id
left join dim_date
    on cast(stg_rentals.rental_date as date) = dim_date.date_actual
          )
        
        ...
[0m16:11:02.898876 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:02.904788 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.fct_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

    select name, type from system.columns where table = 'fct_rentals'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:02.913423 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:02.917494 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.fct_rentals"
[0m16:11:02.920429 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.fct_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`fct_rentals`
        ("rental_skey", "customer_skey", "film_skey", "staff_skey", "store_skey", "date_key", "rental_id", "count_rentals", "rental_duration")

with stg_rentals as (
    select
        rental_id,
        customer_id,
        film_id,
        staff_id,
        rental_date,
        count_rentals,
        rental_duration
    from `adw09_stag`.`stg_rentals`
    
),

dim_customer as (
    select customer_id, customer_skey
    from `adw09_star`.`dim_customer`
),

dim_film as (
    select film_id, film_skey
    from `adw09_star`.`dim_film`
),

dim_staff as (
    select staff_id, staff_skey, store_id
    from `adw09_star`.`dim_staff`
),

dim_store as (
    select store_id, store_skey
    from `adw09_star`.`dim_store`
),

dim_date as (
    select date_actual, date_key
    from `adw09_star`.`dim_date`
)

select
    lower(hex(MD5(toString(coalesce(cast(stg_rentals.rental_id as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey,
    dim_customer.customer_skey,
    dim_film.film_skey,
    dim_staff.staff_skey,
    dim_store.store_skey,
    dim_date.date_key,
    stg_rentals.rental_id,
    stg_rentals.count_rentals,
    stg_rentals.rental_duration
from stg_rentals
left join dim_customer
    on stg_rentals.customer_id = dim_customer.customer_id
left join dim_film
    on stg_rentals.film_id = dim_film.film_id
left join dim_staff
    on stg_rentals.staff_id = dim_staff.staff_id
LEFT JOIN dim_store 
    ON dim_staff.store_id = dim_store.store_id
left join dim_date
    on cast(stg_rentals.rental_date as date) = dim_date.date_actual
  
    ...
[0m16:11:03.161355 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.24 seconds
[0m16:11:03.165720 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d932c03-7531-4c82-b760-847d627a9d13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9874a450>]}
[0m16:11:03.166738 [info ] [Thread-1 (]: 10 of 10 OK created sql incremental model `adw09_star`.`fct_rentals` ........... [[32mOK[0m in 0.32s]
[0m16:11:03.167818 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:11:03.171367 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:11:03.172157 [debug] [MainThread]: Connection 'model.sakstar.fct_rentals' was left open.
[0m16:11:03.172757 [debug] [MainThread]: On model.sakstar.fct_rentals: Close
[0m16:11:03.173649 [info ] [MainThread]: 
[0m16:11:03.174351 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 3.35 seconds (3.35s).
[0m16:11:03.177311 [debug] [MainThread]: Command end result
[0m16:11:03.250160 [info ] [MainThread]: 
[0m16:11:03.251288 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:11:03.252009 [info ] [MainThread]: 
[0m16:11:03.252869 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m16:11:03.255307 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.7435994, "process_in_blocks": "0", "process_kernel_time": 1.059652, "process_mem_max_rss": "207280", "process_out_blocks": "3536", "process_user_time": 6.781777}
[0m16:11:03.256032 [debug] [MainThread]: Command `dbt run` succeeded at 16:11:03.255867 after 4.74 seconds
[0m16:11:03.256746 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1b3c3c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1b6d5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1e1e89ef30>]}
[0m16:11:03.257402 [debug] [MainThread]: Flushing usage events
[0m16:11:49.735088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afe241b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afcdd3e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afc7e01d0>]}


============================== 16:11:49.742031 | c1dc5111-db37-496d-86e7-9016116c23d3 ==============================
[0m16:11:49.742031 [info ] [MainThread]: Running with dbt=1.8.9
[0m16:11:49.743006 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/jovyan/dbt/workspace/logs', 'version_check': 'True', 'profiles_dir': '/home/jovyan/dbt/workspace', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m16:11:50.085353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afd9601a0>]}
[0m16:11:50.208280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afc398f80>]}
[0m16:11:50.209902 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m16:11:50.395085 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m16:11:50.644309 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:11:50.644973 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:11:50.748723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afc252480>]}
[0m16:11:50.982705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afc157ce0>]}
[0m16:11:50.983681 [info ] [MainThread]: Found 10 models, 23 data tests, 1 snapshot, 13 sources, 605 macros
[0m16:11:50.984284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afc116870>]}
[0m16:11:50.990896 [info ] [MainThread]: 
[0m16:11:50.992302 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m16:11:51.005047 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m16:11:51.031041 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:11:51.937342 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:11:51.943992 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:51.975964 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m16:11:51.981567 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:51.987177 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw09_stag)
[0m16:11:51.999554 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_stag'
      

  ...
[0m16:11:52.037877 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m16:11:52.042429 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw09_stag, now list__star)
[0m16:11:52.046310 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'star'
      

  ...
[0m16:11:52.076959 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:52.080687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__star, now list__adw09_star)
[0m16:11:52.086339 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw09_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw09_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw09_star'
      

  ...
[0m16:11:52.115819 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:52.122987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7b249a60>]}
[0m16:11:52.124506 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m16:11:52.125626 [info ] [MainThread]: 
[0m16:11:52.131718 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m16:11:52.133036 [info ] [Thread-1 (]: 1 of 10 START sql view model `adw09_stag`.`stg_customer` ....................... [RUN]
[0m16:11:52.133937 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw09_star, now model.sakstar.stg_customer)
[0m16:11:52.134557 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m16:11:52.175475 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m16:11:52.176726 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m16:11:52.202841 [debug] [Thread-1 (]: Relation stg_customer already exists, replacing it
[0m16:11:52.221017 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m16:11:52.222545 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */


  create or replace view `adw09_stag`.`stg_customer` 
  
    
    
  as (
    

with customers as (
    select
        customer_id,
        store_id,
        first_name as customer_first_name,
        last_name as customer_last_name,
        address_id,
        email as customer_email,
        active as customer_active,
        create_date as customer_create_date,
        last_update as customer_last_update
    from `sakila_dwh`.`customer`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(sc.customer_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(sc.customer_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as customer_skey,
    sc.customer_id,
    sc.customer_first_name,
    sc.customer_last_name,
    sc.customer_email,
    sc.customer_active,
    sa.address as customer_address,
    sa.district as customer_district,
    sa.postal_code as customer_postal_code,
    sa.phone as customer_phone_number,
    scty.city as customer_city,
    sctr.country as customer_country,
    sc.customer_create_date,
    sc.customer_last_update
from customers sc
join address sa
    on sc.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:52.252650 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:52.293478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afd1f5100>]}
[0m16:11:52.294667 [info ] [Thread-1 (]: 1 of 10 OK created sql view model `adw09_stag`.`stg_customer` .................. [[32mOK[0m in 0.16s]
[0m16:11:52.295928 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m16:11:52.296742 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m16:11:52.297565 [info ] [Thread-1 (]: 2 of 10 START sql view model `adw09_stag`.`stg_film` ........................... [RUN]
[0m16:11:52.298692 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m16:11:52.299483 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m16:11:52.311193 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m16:11:52.312418 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m16:11:52.316869 [debug] [Thread-1 (]: Relation stg_film already exists, replacing it
[0m16:11:52.318669 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m16:11:52.320132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */


  create or replace view `adw09_stag`.`stg_film` 
  
    
    
  as (
    

with film_category as (
    select
        film_id,
        category_id,
        last_update as category_last_update
    from `sakila_dwh`.`film_category`
),

category as (
    select
        category_id, 
        name as category_name
    from `sakila_dwh`.`category`
),

language as (
    select
        language_id,
        name as language_name,
        last_update
    from `sakila_dwh`.`language`
),

film as (
    select
        film_id,
        title as film_title,
        description as film_description,
        release_year as film_release_year,
        language_id,
        original_language_id,
        rental_duration,
        rental_rate,
        length as film_duration,
        replacement_cost as film_replacement_cost,
        rating as film_rating,
        special_features as film_special_features,
        last_update as film_last_update
    from `sakila_dwh`.`film`
)

select
    lower(hex(MD5(toString(coalesce(cast(f.film_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(f.film_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as film_skey, 
    f.film_id as film_id,
    f.film_title,
    f.film_description,
    f.film_release_year,
    l.language_name as film_language,
    ol.language_name as film_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.film_duration,
    f.film_replacement_cost,
    f.film_rating,
    f.film_special_features,
    c.category_name as film_category_name,
    f.film_last_update
from film f
join language l
    on f.language_id = l.language_id
join language ol
    on f.original_language_id = ol.language_id
join film_category fc
    on f.film_id = fc.film_id
join category c
    on fc.category_id = c.category_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:52.353163 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:52.357536 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7ad4aff0>]}
[0m16:11:52.358781 [info ] [Thread-1 (]: 2 of 10 OK created sql view model `adw09_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m16:11:52.360208 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m16:11:52.361097 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rentals
[0m16:11:52.361979 [info ] [Thread-1 (]: 3 of 10 START sql view model `adw09_stag`.`stg_rentals` ........................ [RUN]
[0m16:11:52.363311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rentals)
[0m16:11:52.364577 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rentals
[0m16:11:52.376441 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rentals"
[0m16:11:52.377978 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rentals
[0m16:11:52.384000 [debug] [Thread-1 (]: Relation stg_rentals already exists, replacing it
[0m16:11:52.385809 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rentals"
[0m16:11:52.386979 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rentals"} */


  create or replace view `adw09_stag`.`stg_rentals` 
  
    
    
  as (
    

with rental as (
    select *
    from `sakila_dwh`.`rental`
),

inventory as (
    select *
    from `sakila_dwh`.`inventory`
),

staff as (
    select *
    from `sakila_dwh`.`staff`
)

select
    r.rental_id,
    r.customer_id,
    i.film_id,
    r.staff_id as staff_id,               
    s.store_id as store_id,  
    r.rental_date,
    r.return_date,
    1 as count_rentals,
    datediff(day, r.rental_date, r.return_date) as rental_duration,
    lower(hex(MD5(toString(coalesce(cast(r.rental_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(r.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey
from `sakila_dwh`.`rental` r
join `sakila_dwh`.`inventory` i on r.inventory_id = i.inventory_id
join `sakila_dwh`.`staff` s on r.staff_id = s.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:52.412097 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:52.416146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7acf77d0>]}
[0m16:11:52.417280 [info ] [Thread-1 (]: 3 of 10 OK created sql view model `adw09_stag`.`stg_rentals` ................... [[32mOK[0m in 0.05s]
[0m16:11:52.418766 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rentals
[0m16:11:52.419897 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m16:11:52.421263 [info ] [Thread-1 (]: 4 of 10 START sql view model `adw09_stag`.`stg_staff` .......................... [RUN]
[0m16:11:52.422196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rentals, now model.sakstar.stg_staff)
[0m16:11:52.422964 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m16:11:52.433041 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m16:11:52.434210 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m16:11:52.442236 [debug] [Thread-1 (]: Relation stg_staff already exists, replacing it
[0m16:11:52.444539 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m16:11:52.446254 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */


  create or replace view `adw09_stag`.`stg_staff` 
  
    
    
  as (
    

with staff as (
    select
        staff_id,
        first_name,
        last_name,
        address_id,
        email,
        store_id,
        active,
        last_update
    from `sakila_dwh`.`staff`
),

address as (
    select * from `sakila_dwh`.`address`
),

city as (
    select * from `sakila_dwh`.`city`
),

country as (
    select * from `sakila_dwh`.`country`
)

select 
    lower(hex(MD5(toString(coalesce(cast(s.staff_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(s.last_update as String), '_dbt_utils_surrogate_key_null_') )))) as staff_skey,
    s.staff_id,
    s.first_name as staff_first_name,
    s.last_name as staff_last_name,
    a.address as staff_address,
    a.district as staff_district,
    a.postal_code as staff_postal_code,
    a.phone as staff_phone_number,
    c.city as staff_city,
    co.country as staff_country,
    s.email as staff_email,
    s.store_id,
    s.active as staff_active,
    s.last_update as staff_last_update
from staff s
join address a 
    on s.address_id = a.address_id
join city c 
    on a.city_id = c.city_id
join country co 
    on c.country_id = co.country_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:52.477944 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:52.483426 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7ad78110>]}
[0m16:11:52.489922 [info ] [Thread-1 (]: 4 of 10 OK created sql view model `adw09_stag`.`stg_staff` ..................... [[32mOK[0m in 0.06s]
[0m16:11:52.491640 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m16:11:52.492913 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m16:11:52.494588 [info ] [Thread-1 (]: 5 of 10 START sql view model `adw09_stag`.`stg_store` .......................... [RUN]
[0m16:11:52.496346 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m16:11:52.497274 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m16:11:52.509622 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m16:11:52.511540 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m16:11:52.516710 [debug] [Thread-1 (]: Relation stg_store already exists, replacing it
[0m16:11:52.519089 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m16:11:52.521046 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */


  create or replace view `adw09_stag`.`stg_store` 
  
    
    
  as (
    

with store as (
    select
        store_id,
        manager_staff_id,
        address_id,
        last_update as store_last_update
    from `sakila_dwh`.`store`
),

staff as (
    select
        staff_id,
        first_name as store_manager_first_name,
        last_name as store_manager_last_name
    from `sakila_dwh`.`staff`
),

address as (
    select *
    from `sakila_dwh`.`address`
),

city as (
    select *
    from `sakila_dwh`.`city`
),

country as (
    select *
    from `sakila_dwh`.`country`
)

select
    lower(hex(MD5(toString(coalesce(cast(ss.store_id as String), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ss.store_last_update as String), '_dbt_utils_surrogate_key_null_') )))) as store_skey,
    ss.store_id,
    sa.address as store_address,
    sa.district as store_district,
    sa.postal_code as store_postal_code,
    sa.phone as store_phone_number,
    scty.city as store_city,
    sctr.country as store_country,
    ss.manager_staff_id as store_manager_staff_id,
    sst.store_manager_first_name,
    sst.store_manager_last_name,
    ss.store_last_update
from store ss
join address sa
    on ss.address_id = sa.address_id
join city scty
    on sa.city_id = scty.city_id
join country sctr
    on scty.country_id = sctr.country_id
join staff sst
    on ss.manager_staff_id = sst.staff_id
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m16:11:52.555624 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m16:11:52.559318 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7ad4ce90>]}
[0m16:11:52.560532 [info ] [Thread-1 (]: 5 of 10 OK created sql view model `adw09_stag`.`stg_store` ..................... [[32mOK[0m in 0.06s]
[0m16:11:52.561604 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m16:11:52.562371 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m16:11:52.563713 [info ] [Thread-1 (]: 6 of 10 START sql incremental model `adw09_star`.`dim_customer` ................ [RUN]
[0m16:11:52.564869 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m16:11:52.565806 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m16:11:52.591568 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m16:11:52.592915 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m16:11:52.700183 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:11:52.705127 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:52.769595 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw09_star`.`dim_customer__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

          )
        
        ...
[0m16:11:52.789601 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:52.826942 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:52.834194 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:52.841575 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_customer__dbt_new_data`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")

SELECT
    customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_create_date,
    customer_last_update
FROM `adw09_stag`.`stg_customer`


WHERE customer_last_update > (SELECT max(customer_last_update) FROM `adw09_star`.`dim_customer`)

  
      ...
[0m16:11:53.045809 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.20 seconds
[0m16:11:53.048381 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m16:11:53.049833 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

          create table `adw09_star`.`dim_customer__dbt_tmp` 
   as `adw09_star`.`dim_customer__dbt_new_data`
      ...
[0m16:11:53.069685 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:53.076045 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:53.083438 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.087282 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

        insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer`
          where (customer_id) not in (
            select customer_id
            from `adw09_star`.`dim_customer__dbt_new_data`
          )
       
    ...
[0m16:11:53.100747 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.103139 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

     insert into `adw09_star`.`dim_customer__dbt_tmp` ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update")
        select "customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_create_date", "customer_last_update"
        from `adw09_star`.`dim_customer__dbt_new_data`
      
    ...
[0m16:11:53.109907 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.115694 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_new_data` 
  ...
[0m16:11:53.119978 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.132138 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:11:53.136393 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.139383 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    rename table `adw09_star`.`dim_customer__dbt_tmp` to `adw09_star`.`dim_customer__dbt_backup` 
  
  ...
[0m16:11:53.143845 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.152636 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */
EXCHANGE TABLES `adw09_star`.`dim_customer__dbt_backup` AND `adw09_star`.`dim_customer` 
  
  ...
[0m16:11:53.157119 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.163465 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    drop table if exists `adw09_star`.`dim_customer__dbt_backup` 
  ...
[0m16:11:53.167499 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.170510 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7ad4c860>]}
[0m16:11:53.171657 [info ] [Thread-1 (]: 6 of 10 OK created sql incremental model `adw09_star`.`dim_customer` ........... [[32mOK[0m in 0.61s]
[0m16:11:53.172832 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m16:11:53.173635 [debug] [Thread-1 (]: Began running node model.sakstar.dim_film
[0m16:11:53.174557 [info ] [Thread-1 (]: 7 of 10 START sql incremental model `adw09_star`.`dim_film` .................... [RUN]
[0m16:11:53.175729 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_customer, now model.sakstar.dim_film)
[0m16:11:53.176508 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_film
[0m16:11:53.183187 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_film"
[0m16:11:53.184341 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_film
[0m16:11:53.193511 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:11:53.197545 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.201619 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

            

    
        create table `adw09_star`.`dim_film__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

          )
        
        ...
[0m16:11:53.223761 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:53.232988 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:53.240837 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.243644 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_film__dbt_new_data`
        ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")

SELECT
    film_skey,
    film_id,
    film_title,
    film_description,
    film_release_year,
    film_language,
    film_original_language,
    film_rental_duration,
    film_rental_rate,
    film_duration,
    film_replacement_cost,
    film_rating,
    film_special_features,
    film_category_name,
    film_last_update
FROM `adw09_stag`.`stg_film`


WHERE film_last_update > (SELECT max(film_last_update) FROM `adw09_star`.`dim_film`)

  
      ...
[0m16:11:53.397193 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:11:53.399194 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_film"
[0m16:11:53.400614 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

          create table `adw09_star`.`dim_film__dbt_tmp` 
   as `adw09_star`.`dim_film__dbt_new_data`
      ...
[0m16:11:53.418021 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:53.423398 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    select name, type from system.columns where table = 'dim_film'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:53.430685 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.433691 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

        insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film`
          where (film_id) not in (
            select film_id
            from `adw09_star`.`dim_film__dbt_new_data`
          )
       
    ...
[0m16:11:53.442553 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.444838 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

     insert into `adw09_star`.`dim_film__dbt_tmp` ("film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update")
        select "film_skey", "film_id", "film_title", "film_description", "film_release_year", "film_language", "film_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_category_name", "film_last_update"
        from `adw09_star`.`dim_film__dbt_new_data`
      
    ...
[0m16:11:53.450490 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.456251 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_new_data` 
  ...
[0m16:11:53.460909 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.466191 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:11:53.470252 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.472563 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    rename table `adw09_star`.`dim_film__dbt_tmp` to `adw09_star`.`dim_film__dbt_backup` 
  
  ...
[0m16:11:53.476463 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.478635 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */
EXCHANGE TABLES `adw09_star`.`dim_film__dbt_backup` AND `adw09_star`.`dim_film` 
  
  ...
[0m16:11:53.482570 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.489003 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_film"} */

    drop table if exists `adw09_star`.`dim_film__dbt_backup` 
  ...
[0m16:11:53.493347 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.495854 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a793bc6e0>]}
[0m16:11:53.496761 [info ] [Thread-1 (]: 7 of 10 OK created sql incremental model `adw09_star`.`dim_film` ............... [[32mOK[0m in 0.32s]
[0m16:11:53.497832 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_film
[0m16:11:53.498564 [debug] [Thread-1 (]: Began running node model.sakstar.dim_staff
[0m16:11:53.499390 [info ] [Thread-1 (]: 8 of 10 START sql incremental model `adw09_star`.`dim_staff` ................... [RUN]
[0m16:11:53.500574 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_film, now model.sakstar.dim_staff)
[0m16:11:53.501925 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_staff
[0m16:11:53.508284 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_staff"
[0m16:11:53.509330 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_staff
[0m16:11:53.518705 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_new_data` 
  ...
[0m16:11:53.522875 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.525977 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

            

    
        create table `adw09_star`.`dim_staff__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


WHERE staff_last_update > (SELECT max(staff_last_update) FROM `adw09_star`.`dim_staff`)

          )
        
        ...
[0m16:11:53.544933 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:53.551133 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:53.559683 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.562811 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_staff__dbt_new_data`
        ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update")

SELECT
    staff_skey,
    staff_id,
    staff_first_name,
    staff_last_name,
    staff_email,
    store_id,
    staff_active,
    staff_last_update
FROM `adw09_stag`.`stg_staff`


WHERE staff_last_update > (SELECT max(staff_last_update) FROM `adw09_star`.`dim_staff`)

  
      ...
[0m16:11:53.678643 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.12 seconds
[0m16:11:53.680828 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_staff"
[0m16:11:53.682190 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

          create table `adw09_star`.`dim_staff__dbt_tmp` 
   as `adw09_star`.`dim_staff__dbt_new_data`
      ...
[0m16:11:53.700299 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:53.708322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    select name, type from system.columns where table = 'dim_staff'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:53.715880 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.719102 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

        insert into `adw09_star`.`dim_staff__dbt_tmp` ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update")
        select "staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update"
        from `adw09_star`.`dim_staff`
          where (staff_id) not in (
            select staff_id
            from `adw09_star`.`dim_staff__dbt_new_data`
          )
       
    ...
[0m16:11:53.730417 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.732397 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

     insert into `adw09_star`.`dim_staff__dbt_tmp` ("staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update")
        select "staff_skey", "staff_id", "staff_first_name", "staff_last_name", "staff_email", "store_id", "staff_active", "staff_last_update"
        from `adw09_star`.`dim_staff__dbt_new_data`
      
    ...
[0m16:11:53.737767 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.743510 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_new_data` 
  ...
[0m16:11:53.747632 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.753943 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_backup` 
  
  ...
[0m16:11:53.758049 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.760019 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    rename table `adw09_star`.`dim_staff__dbt_tmp` to `adw09_star`.`dim_staff__dbt_backup` 
  
  ...
[0m16:11:53.763548 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.765796 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */
EXCHANGE TABLES `adw09_star`.`dim_staff__dbt_backup` AND `adw09_star`.`dim_staff` 
  
  ...
[0m16:11:53.769990 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.776654 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_staff"} */

    drop table if exists `adw09_star`.`dim_staff__dbt_backup` 
  ...
[0m16:11:53.780509 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.782972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7afa83e0>]}
[0m16:11:53.783921 [info ] [Thread-1 (]: 8 of 10 OK created sql incremental model `adw09_star`.`dim_staff` .............. [[32mOK[0m in 0.28s]
[0m16:11:53.785163 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_staff
[0m16:11:53.786154 [debug] [Thread-1 (]: Began running node model.sakstar.dim_store
[0m16:11:53.787263 [info ] [Thread-1 (]: 9 of 10 START sql incremental model `adw09_star`.`dim_store` ................... [RUN]
[0m16:11:53.788189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_staff, now model.sakstar.dim_store)
[0m16:11:53.789182 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_store
[0m16:11:53.798806 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_store"
[0m16:11:53.800379 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_store
[0m16:11:53.810375 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:11:53.814326 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:53.817695 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

            

    
        create table `adw09_star`.`dim_store__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

          )
        
        ...
[0m16:11:53.839043 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:53.845343 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store__dbt_new_data'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:53.852738 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:53.855799 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        
  
    
    
    
        
         


        insert into `adw09_star`.`dim_store__dbt_new_data`
        ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")

SELECT
    store_skey,
    store_id,
    store_address,
    store_district,
    store_postal_code,
    store_phone_number,
    store_city,
    store_country,
    store_manager_staff_id,
    store_manager_first_name,
    store_manager_last_name,
    store_last_update
FROM `adw09_stag`.`stg_store`


WHERE store_last_update > (SELECT max(store_last_update) FROM `adw09_star`.`dim_store`)

  
      ...
[0m16:11:54.008399 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.15 seconds
[0m16:11:54.010702 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_store"
[0m16:11:54.012216 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

          create table `adw09_star`.`dim_store__dbt_tmp` 
   as `adw09_star`.`dim_store__dbt_new_data`
      ...
[0m16:11:54.030982 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m16:11:54.036355 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    select name, type from system.columns where table = 'dim_store'
    
      and database = 'adw09_star'
    
    order by position
  ...
[0m16:11:54.044159 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:54.047002 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

        insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store`
          where (store_id) not in (
            select store_id
            from `adw09_star`.`dim_store__dbt_new_data`
          )
       
    ...
[0m16:11:54.059906 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:54.062377 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

     insert into `adw09_star`.`dim_store__dbt_tmp` ("store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")
        select "store_skey", "store_id", "store_address", "store_district", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update"
        from `adw09_star`.`dim_store__dbt_new_data`
      
    ...
[0m16:11:54.068671 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m16:11:54.089512 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_new_data` 
  ...
[0m16:11:54.095210 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:54.101894 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:11:54.106417 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:54.108215 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    rename table `adw09_star`.`dim_store__dbt_tmp` to `adw09_star`.`dim_store__dbt_backup` 
  
  ...
[0m16:11:54.112253 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:54.114026 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */
EXCHANGE TABLES `adw09_star`.`dim_store__dbt_backup` AND `adw09_star`.`dim_store` 
  
  ...
[0m16:11:54.117630 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:54.124947 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_store"} */

    drop table if exists `adw09_star`.`dim_store__dbt_backup` 
  ...
[0m16:11:54.129038 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:54.131577 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a794762d0>]}
[0m16:11:54.132659 [info ] [Thread-1 (]: 9 of 10 OK created sql incremental model `adw09_star`.`dim_store` .............. [[32mOK[0m in 0.34s]
[0m16:11:54.133716 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_store
[0m16:11:54.135970 [debug] [Thread-1 (]: Began running node model.sakstar.fct_rentals
[0m16:11:54.136836 [info ] [Thread-1 (]: 10 of 10 START sql incremental model `adw09_star`.`fct_rentals` ................ [RUN]
[0m16:11:54.137688 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.dim_store, now model.sakstar.fct_rentals)
[0m16:11:54.138447 [debug] [Thread-1 (]: Began compiling node model.sakstar.fct_rentals
[0m16:11:54.148255 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.fct_rentals"
[0m16:11:54.149450 [debug] [Thread-1 (]: Began executing node model.sakstar.fct_rentals
[0m16:11:54.159926 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.fct_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

    drop table if exists `adw09_star`.`fct_rentals__dbt_new_data` 
  ...
[0m16:11:54.164179 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m16:11:54.167899 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.fct_rentals: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

            

    
        create table `adw09_star`.`fct_rentals__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

with stg_rentals as (
    select
        rental_id,
        customer_id,
        film_id,
        staff_id,
        rental_date,
        count_rentals,
        rental_duration
    from `adw09_stag`.`stg_rentals`
    
    where rental_date > (select max(rental_date) from `adw09_star`.`fct_rentals`)
    
),

dim_customer as (
    select customer_id, customer_skey
    from `adw09_star`.`dim_customer`
),

dim_film as (
    select film_id, film_skey
    from `adw09_star`.`dim_film`
),

dim_staff as (
    select staff_id, staff_skey, store_id
    from `adw09_star`.`dim_staff`
),

dim_store as (
    select store_id, store_skey
    from `adw09_star`.`dim_store`
),

dim_date as (
    select date_actual, date_key
    from `adw09_star`.`dim_date`
)

select
    lower(hex(MD5(toString(coalesce(cast(stg_rentals.rental_id as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey,
    dim_customer.customer_skey,
    dim_film.film_skey,
    dim_staff.staff_skey,
    dim_store.store_skey,
    dim_date.date_key,
    stg_rentals.rental_id,
    stg_rentals.count_rentals,
    stg_rentals.rental_duration
from stg_rentals
left join dim_customer
    on stg_rentals.customer_id = dim_customer.customer_id
left join dim_film
    on stg_rentals.film_id = dim_film.film_id
left join dim_staff
    on stg_rentals.staff_id = dim_staff.staff_id
LEFT JOIN dim_store 
    ON dim_staff.store_id = dim_store.store_id
left join dim_date
    on cast(stg_rentals.rental_date as date) = dim_date.date_actual
          )
        
        ...
[0m16:11:54.177688 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.fct_rentals"} */

            

    
        create table `adw09_star`.`fct_rentals__dbt_new_data`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

with stg_rentals as (
    select
        rental_id,
        customer_id,
        film_id,
        staff_id,
        rental_date,
        count_rentals,
        rental_duration
    from `adw09_stag`.`stg_rentals`
    
    where rental_date > (select max(rental_date) from `adw09_star`.`fct_rentals`)
    
),

dim_customer as (
    select customer_id, customer_skey
    from `adw09_star`.`dim_customer`
),

dim_film as (
    select film_id, film_skey
    from `adw09_star`.`dim_film`
),

dim_staff as (
    select staff_id, staff_skey, store_id
    from `adw09_star`.`dim_staff`
),

dim_store as (
    select store_id, store_skey
    from `adw09_star`.`dim_store`
),

dim_date as (
    select date_actual, date_key
    from `adw09_star`.`dim_date`
)

select
    lower(hex(MD5(toString(coalesce(cast(stg_rentals.rental_id as String), '_dbt_utils_surrogate_key_null_') )))) as rental_skey,
    dim_customer.customer_skey,
    dim_film.film_skey,
    dim_staff.staff_skey,
    dim_store.store_skey,
    dim_date.date_key,
    stg_rentals.rental_id,
    stg_rentals.count_rentals,
    stg_rentals.rental_duration
from stg_rentals
left join dim_customer
    on stg_rentals.customer_id = dim_customer.customer_id
left join dim_film
    on stg_rentals.film_id = dim_film.film_id
left join dim_staff
    on stg_rentals.staff_id = dim_staff.staff_id
LEFT JOIN dim_store 
    ON dim_staff.store_id = dim_store.store_id
left join dim_date
    on cast(stg_rentals.rental_date as date) = dim_date.date_actual
          )
        
        
[0m16:11:54.189171 [debug] [Thread-1 (]: Database Error in model fct_rentals (models/marts/fact/fct_rentals/fct_rentals.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 1
   Code: 1. DB::Exception: Resolved identifier 'rental_date' in parent scope to expression 'adw09_stag.stg_rentals.rental_date' with correlated column 'rental_date' (Enable 'allow_experimental_correlated_subqueries' setting to allow correlated subqueries execution). In scope (SELECT max(rental_date) FROM adw09_star.fct_rentals). (UNSUPPORTED_METHOD) (version 25.4.1.2934 (official build))
[0m16:11:54.190280 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c1dc5111-db37-496d-86e7-9016116c23d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a7ae38d40>]}
[0m16:11:54.191315 [error] [Thread-1 (]: 10 of 10 ERROR creating sql incremental model `adw09_star`.`fct_rentals` ....... [[31mERROR[0m in 0.05s]
[0m16:11:54.192550 [debug] [Thread-1 (]: Finished running node model.sakstar.fct_rentals
[0m16:11:54.196549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:11:54.197081 [debug] [MainThread]: Connection 'model.sakstar.fct_rentals' was left open.
[0m16:11:54.197767 [debug] [MainThread]: On model.sakstar.fct_rentals: Close
[0m16:11:54.198605 [info ] [MainThread]: 
[0m16:11:54.199371 [info ] [MainThread]: Finished running 5 view models, 5 incremental models in 0 hours 0 minutes and 3.21 seconds (3.21s).
[0m16:11:54.204431 [debug] [MainThread]: Command end result
[0m16:11:54.277528 [info ] [MainThread]: 
[0m16:11:54.278490 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m16:11:54.279194 [info ] [MainThread]: 
[0m16:11:54.280123 [error] [MainThread]:   Database Error in model fct_rentals (models/marts/fact/fct_rentals/fct_rentals.sql)
  HTTPDriver for http://clickhouse:8123 received ClickHouse error code 1
   Code: 1. DB::Exception: Resolved identifier 'rental_date' in parent scope to expression 'adw09_stag.stg_rentals.rental_date' with correlated column 'rental_date' (Enable 'allow_experimental_correlated_subqueries' setting to allow correlated subqueries execution). In scope (SELECT max(rental_date) FROM adw09_star.fct_rentals). (UNSUPPORTED_METHOD) (version 25.4.1.2934 (official build))
[0m16:11:54.280842 [info ] [MainThread]: 
[0m16:11:54.281541 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=1 SKIP=0 TOTAL=10
[0m16:11:54.283174 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.6382327, "process_in_blocks": "0", "process_kernel_time": 1.159596, "process_mem_max_rss": "207436", "process_out_blocks": "3544", "process_user_time": 6.927591}
[0m16:11:54.283956 [debug] [MainThread]: Command `dbt run` failed at 16:11:54.283727 after 4.64 seconds
[0m16:11:54.284543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afcbb59d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afd18d4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3afd18ec60>]}
[0m16:11:54.285377 [debug] [MainThread]: Flushing usage events
